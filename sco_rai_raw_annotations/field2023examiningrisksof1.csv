,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{field2023examiningrisksof,
    author = {Anjalie Field and Amanda Coston and Nupoor Gandhi and Alexandra Chouldechova and David Steier and Emily Putnam-Hornstein and Yulia Tsvetkov},
    title = {Examining risks of racial biases in NLP tools for child protective services},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-08, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,CPSAgencies,Agent,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,CPS agencies ,
10,FreeFormNotes,Artifact,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,copious free-form text notes,
11,CPSWorkers,Agent,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,CPS workers,
12,FamilyNeeds,Perceived_Need,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,family situations and needs ,
13,ChallengeOfManualReviews,Perceived_Problem,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,manual reviews of notes is challenging,
14,CaseworkerTurnover,Perceived_Problem,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,higher caseworker turnover,
15,NegitiveExeperienceChildren,Perceived_Problem,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,worse experiences for affected children,
16,DemandForNLP,Perceived_Need,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,actively seeking NLP tools,
17,Families,Agent,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-81,families involved in CPS,
18,Researchers,Agent,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,we,
19,Mistrust,Causal_Theory,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"express mistrust in “the system""",
20,RacialPerformanceDisparities,Perceived_Need,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,disparities in model performance,
21,NoteDataset,Artifact,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"a data set of 3,105,071 contact notes",
22,NoDifferences,Causal_Theory,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,there are not consistent differences by race in data set sizes,
23, , , , , ,
24,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
25,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
26,CPSWorkers,hasProducedArtifact,FreeFormNotes,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,copious free-form text notes written by CPS workers
27,CPSWorkers,hasProducedArtifact,NoteDataset,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers"
28,FamilyNeeds,constrainsAgent,CPSAgencies,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs"
29,ChallengeOfManualReviews,constrainsAgent,CPSAgencies,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]."
30,CaseworkerTurnover,constrainsAgent,CPSAgencies,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover "
31,NegitiveExeperienceChildren,constrainsAgent,CPSAgencies,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with [...] worse experiences for affected children"
32,DemandForNLP,constrainsAgent,CPSAgencies,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,CPS agencies are actively seeking NLP tools
33,Mistrust,constrainsAgent,Families,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,families involved in CPS already express mistrust in “the system
34,RacialPerformanceDisparities,constrainsAgent,Researchers,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,We focus specifically on disparities in model performance over case notes about black and white families
35,NoDifferences,constrainsAgent,Researchers,"CPS agencies have copious free-form text notes written by CPS workers, which contain extensive details, including professional assessments of family situations and needs [14, 52].Undirected manual reviews of notes is challenging for caseworkers and supervisors when, for example, making time-sensitive decisions or examining a newly assigned case [42]. Further, needing to spend time on administrative tasks like reviewing notes rather than working directly with families is associated with higher caseworker turnover and worse experiences for affected children [56, 57]. As the potential for NLP to aid in processing expert-written notes has been demonstrated in domains like healthcare and law [26, 28, 59, 66], CPS agencies are actively seeking NLP tools to extract and deliver information from unstructured data [24, 40, 42, 61], and some research has additionally discussed implications of leveraging these data in predictive risk models [52, 53]. Predictive risk models have already been implemented to inform various aspects of CPS practice, such as which allegations are screened-in for investigation [10, 38, 52] or which investigations are prioritized for supervisoryreview [44], but existing models primarily rely on tabular structured data [52].In this work, we examine the algorithmic fairness of NLP technology in CPS settings. Research on NLP model performance over real high stakes data is extremely difficult, given challenges around data privacy and forming partnerships with practitioners. Unlike research that constructs data sets to probe NLP model bias, our work serves as a rare opportunity to benchmark biases in a realistic setting. Furthermore, families involved in CPS already express mistrust in “the system” [3] and there is pronounced criticism of using algorithmic tools in any capacity [18]. Thus, our work is also a timely exploration of one potential risk of deploying NLP in CPS settings: algorithmic unfairness.We focus specifically on disparities in model performance over case notes about black and white families based on decades of research demonstrating racial disparities in the child protection system in the United States [15, 22, 39, 47, 48, 62]. In comparison to white children, black children are disproportionately involved in the system [12], they may be more likely to be reported for abuse by doctors even with similarly severe injuries [31], their referrals are investigated at higher rates [5], and in some states they are placed in foster care at higher rates [6]. Institutional racism in child protective services has also been attributed to the links between the child protection system and other systems like mental health services, criminal justice, and education [22]. We investigate how deployed NLP models may amplify these disparities. [...] In this work, we investigate a data set of 3,105,071 contact notes,which consists of all contact notes written by CPS workers in theDepartment of Human Services (DHS) in an anonymous county from approximately 2010 to November 23, 2020 (notes prior to 2010 were inconsistently digitized in the current system). Table 1 presents overview statistics of the data. Contact notes log communication between CPS workers and families. As shown in Figure 1, most notes record telephone or face-to-face contacts, such as visiting families at home or school, but notes can also be created for other forms of contact, such as emails. In addition to the primary data, we also reference associated meta-data, such as case open and close dates,lists of associated clients, and mappings between cases, referrals,and clients. Throughout this work, when we refer separately to referral notes and case notes we generally do not duplicate data, e.g.for a referral that turned into a case, we would not consider notes associated with the referral as also associated with the case, which is consistent with DHS data organization. Figure 2 reports the average number of words and word-count histograms in contact notes associated with clients of different races on referrals and cases. Generally, there are not consistent differences by race in data set sizes. Although there tends to be more text data for white-associated cases (69.86/day compared to 50.81/day), there tends to be more text data for black-associated referrals (1,485.13 compared to 1,323.96)",1479-80,"we investigate a data set of 3,105,071 contact notes [...] Generally, there are not consistent differences by race in data set sizes"
