,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{kwegyireaggrey2023, author = {Kwegyir-Aggrey, Kweku and Gerchick, Marissa and Mohan, Malika and Horowitz, Aaron and Venkatasubramanian, Suresh},
title = {The Misuse of AUC: What High Impact Risk Assessment Gets Wrong},
year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,ChildWelfareAgencies,Agent,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,child welfare agencies in the U.S.,
10,EntrenchedDiscrimination,Perceived_Problem,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,marked by entrenched discrimination,
11,PredictiveTools,Strategy,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,These types of tools,
12,AUCForModelSelection,Strategy,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,AUC was used for model selection,
13,AUCForModelPerformance,Strategy,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race",
14,PredictiveToolDeployment,Artifact,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,increasingly us-ing predictive tools in their decision-making processes,
15,Organizations,Agent,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,many organizations,
16,LACounty,Agent,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,Los Angeles County,
17,AlleghenyCounty,Agent,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"Allegheny County, Pennsylvania",
18,DouglasCounty,Agent,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"Douglas County, Colorado",
19, , , , , ,
20,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
21,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
22,ChildWelfareAgencies,hasProducedArtifact,PredictiveToolDeployment,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes
23,EntrenchedDiscrimination,constrainsAgent,Organizations,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination
24,PredictiveTools,constrainsAgent,ChildWelfareAgencies,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations."
25,AUCForModelSelection,constrainsAgent,LACounty,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection"
26,AUCForModelPerformance,constrainsAgent,AlleghenyCounty,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]"
27,AUCForModelPerformance,constrainsAgent,DouglasCounty,"Although child welfare agencies in the U.S. are increasingly us-ing predictive tools in their decision-making processes [86], many organizations have raised concerns about these tools and their use in child welfare systems marked by entrenched discrimination [1, 35, 39, 87, 91, 102].10 These types of tools are used by child welfare agencies at various decision-making points, including in-forming screening decisions, where call screening workers at child welfare agencies evaluate allegations of neglect and decide whether to investigate those allegations. In this context, risk assessments are sometimes used to estimate the likelihood that a child will be removed from their home within a certain time period following a referral to a child welfare agency [86]. Here, we’ll describe the use of AUC in connection with this type of risk assessment deployed in Los Angeles County, California [78], Douglas County, Colorado[98], and Allegheny County, Pennsylvania [99], connecting these uses to some of the issues described in Section 4.The use of each of these risk assessments relies on AUC as an important metric (though not the only metric) in model develop-ment and evaluation, often using samples characterized by severe class imbalance. For the LA Risk Stratification Tool [78], developed in the last several years and recently piloted in several areas of Los Angeles County, AUC was used for model selection [78, p. 13] and to evaluate the model’s fairness by calculating race-specificAUC values [78, p. 15]. The reported AUC value for the chosen model was .83, and the sample was highly imbalanced (13.8% of the sample experienced removal from their homes) [78, p. 15]). For The Allegheny Family Screening Tool (AFST), which has been in use in Allegheny County, Pennsylvania since 2016 [100], AUC has been used for several versions of the model to measure model fit[100, p. 14], perform model selection [99, p. 7], and compute group-specific AUC by race [100, p. 14], [99, p. 7]. In one instance, thetool developers state their finding of a higher AUC (.77) for non-Black children compared to Black children (.74), “suggest[s] that the tool was slightly better at predicting outcomes for non-black children than for black children” [99, p. 7]. For the version of the tool described in [99], the overall AUC value was .76 [99, p. 7] on atesting sample where approximately 1 in 8 children where removed from their homes within two years [100, p. 7]. Lastly, for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics. The AUC results for the considered model architectures varied from .80 to .86 [98, p. 18], and in this instance, the sample used to compute these AUCs may have also been highly imbalanced. 11In these examples, the comparison of race-specific AUC to analyze algorithmic fairness may be misleading, as discussed in Section 4.3.",1577-8,"for a similar tool currently in use in Douglas County, Colorado – the DouglasCounty Decision Aide (DCDA) [98] – AUC is used to evaluate “model performance,” alongside other metrics."
