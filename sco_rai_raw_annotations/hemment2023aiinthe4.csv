,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{hemment2023aiinthe,
    author = {Drew Hemment and Morgan Currie and SJ Bennett and Jake Elwes and Anna Ridler and Caroline Sinders and Matjaz Vidmar and Robin Hill and Holly Warner},
    title = {AI in the Public Eye: Investigating Public AI Literacy Through AI Art},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-10, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,Inaccessibility,Perceived_Problem,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,cautioned against assuming all audiences will find such artworks accessible,
10,DifferentTacticsAndContexts,Other_Precept,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,different tactics and contexts to present a work.,
11,BlackBoxSystems,Artifact,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,many black box systems,
12,AssumedLackOfScientificKnowledge,Perceived_Need,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,the assumption that people don’t like science because they don’t understand science or they don’t know enough about science,
13,AIArtworks,Artifact,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,AI Artworks,
14,Data,Artifact,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,the data,
15,Humans,Agent,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,human,
16,ArtisticMetaphor,Artifact,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,artistic metaphor,
17,MarginalizedAudiences,Agent,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"So that’s, you know, hard to reach groups, marginalized subsections of the population",
18,DiverseAudiences,Agent,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,diverse audiences,
19,ExperiencedWithoutExplanation,Perceived_Need,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,don't need explaining in order to be experienced ,
20,People,Agent,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,people,
21,TooTechnicallySimple,Perceived_Problem,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers",
22,Bias,Causal_Theory,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,bias,
23,MisrepresentationOfAI,Causal_Theory,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors",
24, , , , , ,
25,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
26,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
27,Inaccessibility,constrainsAgent,MarginalizedAudiences,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the population"
28,DifferentTacticsAndContexts,constrainsAgent,DiverseAudiences,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,that reaching diverse audiences may require different tactics and contexts to present a work.
29,BlackBoxSystems,reflectsPrecept,ExperiencedWithoutExplanation,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,many black box systems don't need explaining in order to be experienced
30,AssumedLackOfScientificKnowledge,constrainsAgent,People,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence."
31,AIArtworks,reflectsPrecept,TooTechnicallySimple,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers"
32,Data,reflectsPrecept,Bias,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,bias in the data
33,Humans,hasProducedArtifact,Data,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,there’s immense human effort in collecting the data
34,ArtisticMetaphor,reflectsPrecept,MisrepresentationOfAI,"Finally, we detail cautionary points and limitations of the strategies discussed, both with regards to general audiences and interactions between artists and AI engineers. One participant (participant 8), a social scientist, cautioned against assuming all audiences will find such artworks accessible: I think there needs to be a recognition of the plurality of different audiences [...] So that’s, you know, hard to reach groups, marginalized subsections of the pop-ulation, as well as the audiences that would include activists and those that are more interested, such aspractitioners.This comment acted as a reminder that artists should not assume a singular audience and that reaching diverse audiences may require different tactics and contexts to present a work.Participant 6 pointed out that many black box systems don't need explaining in order to be experienced – “we are perfectly happy to not understand anything about a plane and get on it.”Participant 3, a social scientist, challenged the claim that audiences need to be demystified, as if they did not already understand.Something we talk about in science and technology studies which is the deficit model, the assumption that people don’t like science because they don’t understand science or they don’t know enough about science. And often that is an assumption, it’s not based on any kind of evidence. And assumptions are prob-lematic.At the same time, some participants worried that the assumption that art could influence ML designers was overly optimistic – par-ticipant 7 said she found art “self-contained” and didn’t understand how it could interact with her work as an engineer. Participant 5 said that the themes raised by many AI artworks were too technically simple and, while they may address public literacies, they wouldn't necessarily create an exchange with engineers and designers:I worry that to some extent these kinds of demonstra-tions might just hit a superficial aspect of algorithms and not really go deeper because they are not ask-ing the right questions. They’re kind of saying, yes,there’s bias in the data, yes, there’s immense human effort in collecting the data and it’s something we recognise, but at the point where we need to say, okay,what can we take back to science, I kind of worry that this sometimes falls short.That same participant made the point, however, that creative and experiential exploration of the materiality of AI is one way to deepen discussions with ML designers. To him, problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors:We should be careful to not give people the impression that, you know, this is way ahead, this is where the machines are dreaming and whatnot. And then you are in the zone when we simply cannot even have a current conversation with science.",938-9,"problems arise when artistic metaphor departs from the science or invents or amplifies misrepresentations of AI. A mistake some artists have made is relying on metaphors of machine consciousness or dreaming,contributing to mystification specifically through using anthropo-morphised language and metaphors"
