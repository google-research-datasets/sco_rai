,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{neumann2023doesaiassisted,
    author = {Terrence Neumann and Nicholas Wolczynski},
    title = {Does AI-Assisted Fact-Checking Disproportionately Benefit Majority Groups Online?},
    year = 2023
}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-19, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,HumanAICollaboration,Agent,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,human-AI collaboration in which AI is trained by crowd-workers,
10,NaturalLanguageProcessing,Agent,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,natural language processing (NLP),
11,DisproportionateEffectOfMisinformation,Perceived_Problem,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,Misinformation [...] disproportionately affects ,
12,Researchers,Agent,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,we,
13,BenefitFromRepresentativeLabelling,Strategy,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data.,
14,BenefitFromKnowledgeableLabelling,Strategy,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,Knowledgeable Community Labeling approach significantly improves the outcomes,
15,ClassificationOfMisinformation,Artifact,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,which content should be further evaluated by professional fact-checkers,
16,DetectionOfMisinformation,Artifact,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,spot repeated mentions of misinformation and reduce their circulation online,
17,MinorityCommunities,Agent,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,minority communities online,
18,TACIT,Artifact,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,"the Topic-Aware, Community-Impacted Twitter (TACIT) simulator",
19,MajorityCommunity,Agent,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,majority community,
20, , , , , ,
21, , , , , ,
22, , , , , ,
23,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
24,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
25,HumanAICollaboration,hasProducedArtifact,ClassificationOfMisinformation,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers
26,NaturalLanguageProcessing,hasProducedArtifact,DetectionOfMisinformation,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,"After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online"
27,DisproportionateEffectOfMisinformation,constrainsAgent,MinorityCommunities,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,Misinformation [...] disproportionately affects minority communities online
28,Researchers,hasProducedArtifact,TACIT,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,"we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator"
29,BenefitFromRepresentativeLabelling,constrainsAgent,MajorityCommunity,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data.
30,BenefitFromKnowledgeableLabelling,constrainsAgent,MinorityCommunities,"Misinformation continues to propagate widely on social media,causing significant uncertainty, disagreement, and, at times, violence around critical events. Recent efforts to combat the spread of falsehoods online have involved human-AI collaboration in which AI is trained by crowd-workers to determine which content should be further evaluated by professional fact-checkers [4, 41]. After Claims are fact-checked, natural language processing (NLP) is used to spot repeated mentions of misinformation and reduce their circulation online [2, 18]. This approach has enabled scalable misin-formation detection online, with Facebook labeling hundreds of millions of posts related to national elections and public health as potentially misleading [36, 37]. However, there are growing concerns about mis- and disinforma-tion ‚Äúslipping through the cracks‚Äù and disproportionately affects minority communities online, with a Senate Intelligence report citing that ‚Äúno single group of Americans was targeted ... more than African Americans. By far, race and related issues were the preferred target of the information warfare campaign designed to divide the country in 2016‚Äù [1, pg.6]. Similarly, we see concerns in Europe regarding the continued circulation of persistent false narratives of particular migrant communities [44].To date, the majority of work on fact-checking algorithms used to identify ‚Äúcheck-worthy‚Äù claims circulating online has focused on designing models that have high accuracy on test sets of previously fact-checked claims [5, 21, 29, 34]. However, prior work has not considered whether these AI tools provide equal benefit to all people when deployed. We ask whether algorithms used to assist fact-checkers tend to identify falsehoods that impact major-ity groups while allowing misinformation that impacts minority groups to proliferate relatively unimpeded. Additionally, we in-vestigate whether explicitly incorporating notions of diversity (as discussed in Fazelpour and De-Arteaga [19]) into the training data and AI-assisted fact-checking workflow improves overall outcomes and affects the distribution of benefits from fact-checking.To answer these questions, we develop a novel agent-based methodology for simulating the spread and consumption of multi-topic information across networks - the Topic-Aware, Community-Impacted Twitter (TACIT) simulator - detailed in Section 3. We Use the ‚Äúconstruct‚Äù model of social influence and reasoning [11] to guide probabilistic information consumption and propagation behaviors for agents in the simulation, and we build upon other recent simulation efforts [7] to consider a multi-topic information environ-ment in which communities are particularly impacted by certain topics of information. We run this simulation on a Twitter followers dataset with a strong community structure [16], and we tune the parameters of our simulation so it exhibits the emergence of infor-mation cascades of similar depth, width, and overall engagement to those derived from prior analysis of how true and false information spreads online [46]. In Section 4, we assess the network-wide and group-level efficacy of different check-worthiness algorithms that explicitly account for relevant notions of diversity. We find that both representative and egalitarian methods for sampling and la-beling training data can lead to network-wide benefit concentrated in majority communities, while incorporating diversity into howfact-checkers use algorithmic recommendations actively reduce inequalities in benefits between majority and minority communities. [...] In order to investigate our research question, we run TACIT on a Twitter followers network dataset with a strong (albeit not ground-truth) community structure that accounts for roughly 75% of the 450,000 Twitter users first analyzed in De Domenico et al. [16].From this dataset, we focus specifically on three communities: a large majority community and two smaller minority communities,displayed in Figure 2A, with average community statistics in Figure 2C.We investigate a world in which there exists a majority commu-nity, a minority community, and a small expert community [22, 39].We further assume that |Œ©| = 2, with the majority community being more impacted by ùúî0 and the minority community being more impacted by ùúî1. Additionally, in this world, both majority and minority communities are equally un-knowledgeable about allùúî ‚àà Œ©. The only community with consistent ground-truth knowl-edge about the topics is the small expert community, who is equally impacted by both topics. This is reflected by the parameter settings shown in Figure 2B. While the communities and topics are abstract values within the simulation, they represent possible real-world scenarios. For example, imagine that the network represents Twitter users that are interested in labor law in the United States, and that the majority community are mostly U.S. citizens while the minority community are mostly immigrants working in the U.S. ùúî0can represent claims about labor laws pertaining to U.S. citizens(e.g. rumored changes to collective bargaining rights for workers of large U.S.-based corporations), while ùúî1 can represent claims about immigrant labor laws (e.g. rumored changes to H-2B work permits.) These topics should impact the majority and minority communities in our network differently. Finally, the expert commu-nity in this context could be U.S. lawyers and lawmakers working on labor-related issues. Does the Majority Community Disproportionately Benefit? As Shown in Table 1 and Figure 4, the majority community indeed disproportionately benefits under ‚Äúrepresentative‚Äù (Random LabelSampling and Virality Claim Sampling) and ‚Äúegalitarian‚Äù (StratifiedLabel Sampling and Stratified Virality Sampling) methods for assembling training data. Egalitarian methods for both claim sampling and label sampling lead to significantly higher network-wide bene-fit, but this benefit is more concentrated in the majority community compared to representative diversity components. For example, inTable 1 we see a network-wide benefit of ‚àí0.013 from switching from Virality Sampling to Stratified Virality Sampling. However,after this switch, the minority community‚Äôs outcomes improve only by ‚àí0.004, while the majority group‚Äôs outcomes improve by ‚àí0.017,leading to an increased disparity ratio in treatment effects from 1.33 to 1.86. This provides suggestive evidence that, as the U.S. Sen-ate [1] and European Union [44] sponsored research has pointed out, misinformation that impacts minority groups may be falling through the cracks at a higher rate than for majority groups online.The (Equal) Value of Knowledgeable Online Communities. There Is an overwhelming benefit to using knowledgeable labelers to as-sess the perceived check-worthiness of claims. As shown in Table1, the Knowledgeable Community Labeling approach leads to an additional ‚àí0.026 and ‚àí0.015 network-wide benefit compared to random and stratified approaches. This network-wide increase in benefit is more equally distributed among the majority and minor-ity communities with a treatment effect disparity ratio of 1.5 using Knowledgeable Community labelers compared to disparity ratio of 1.7 and 1.82 for Random Labels and Stratified Labels respectively. Therefore, the Knowledgeable Community Labeling approach sig-nificantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested. While this is an intuitive result, it demonstrates how certain communities of users on a platform can perform a valuable service by providing their opinions, and it points to a way forward after other recent attempt at crowd-sourcing check-worthy claims were largely unsuccessful[4].The Role of AI Predictions in Fact-Checker Workflow. The data inTable 1 show that by switching from always fact-checking the topùëõ predicted claims (regardless of topic) to always fact-checking the top ùëõ/|Œ©| predicted claims for each ùúî ‚àà Œ©, fact-checkers can ac-tively reduce the inequality in benefits from fact-checking. However,this comes at a cost to the network as a whole. From the results,switching from Top Predicted to Top Predicted by Topic decreases the average treatment effect of the majority group by +0.006 and it increases the minority average treatment effect by ‚àí0.004, leading to a drop in disparity ratio of treatment effects from 1.94 to 1.32and a reduction in network-wide average treatment effect of +0.005.A key implication is that if fact-checkers can identify how differ-ent topics impact different online communities, they can control the distribution of benefits amongst these communities by choos-ing a specific level of topic representation in the set of claims they choose to fact-check. By choosing to fact-check topics relevant only to the majority community, you can still improve average outcomes across the network, but it will significantly increase the disparity in treatment for minority groups impacted by other topics that fact-checkers tend not to write about. If there are minority groups that are particularly at risk of being harmed by misinformation or who are particularly uninformed about topics, it is likely ethical and warranted to divert attention to fact-checking topics relevant to these communities.",480-1,Knowledgeable Community Labeling approach significantly improves the outcomes across the network while also decreasing the relative disparity in treatment effects between com-munities compared to the other methods we tested.
