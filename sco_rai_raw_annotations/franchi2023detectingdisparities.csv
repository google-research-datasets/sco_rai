,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{franchi2023detectingdisparities,
    author = {Matt Franchi and J.D. Zamfirescu-Pereira and Wendy Ju and Emma Pierson},
    title = {Detecting disparities in police deployments using dashcam data},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-12, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,PoliceAccountability,Perceived_Problem,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",hold the police to account,
10,Citizens,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",citizens,
11,StatisticalAnalysis,Artifact,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",Statistical analysis of police data ,
12,Police,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",the police,
13,Bias,Causal_Theory,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",bias,
14,Researchers,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",We,
15,HeavyPolicePresence,Strategy,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",high police deployments,
16,Nexar,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives ",
17,ReductionInLASearches,Strategy,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias,
18,ChicagoConsentDecree,Strategy,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71],
19,Arrests,Artifact,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",crimes are more likely to result in arrests.,
20,JudicialAlgorithms,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62]",
21,WebcamPoliceDetection,Artifact,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes.,
22,PolicingDisparityEvidence,Perceived_Problem,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",analysis reveals substantial disparities in police deployments:,
23,HighIncomeCommercial,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","dense,high-income, commercial area",
24,BlackAndHispanic,Agent,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs)",
25,DashcamData,Artifact,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020",
26, , , , , ,
27,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
28,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
29,PoliceAccountability,constrainsAgent,Citizens,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",citizens hold the police to account
30,StatisticalAnalysis,influencesPrecept,PolicingDisparityEvidence,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect"
31,StatisticalAnalysis,influencesPrecept,ReductionInLASearches,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias
32,StatisticalAnalysis,influencesPrecept,ChicagoConsentDecree,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",These statistical analyses have been instrumental to driving policy change and police reform: examples include [...] a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]
33,Police,hasProducedArtifact,Arrests,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","If an area has a heavier police presence, crimes are more likely to result in arrests."
34,Bias,constrainsAgent,JudicialAlgorithms,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62]"
35,Researchers,hasProducedArtifact,WebcamPoliceDetection,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536",We introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes.
36,HeavyPolicePresence,constrainsAgent,HighIncomeCommercial,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Two very different types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. "
37,HeavyPolicePresence,constrainsAgent,BlackAndHispanic,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Two very different types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. "
38,Nexar,hasProducedArtifact,DashcamData,"How do citizens hold the police to account, ensuring that they are equitably protecting those they serve? A vital tool in the struggle for police accountability has been data shedding light on police activity. Statistical analysis of police data has been used to document disparities in police stops, searches, use of force, and respect [2, 25, 27–29, 52, 53, 64, 73]. These statistical analyses have been instrumental to driving policy change and police reform: examples include a reduction in random police searches in Los Angeles following a statistical investigation documenting racial bias [9, 56] and a consent decree in Chicago following a Department of Justice Investigation documenting numerous rights violations [71]. In recent years, policing datasets have become more widely available to the public [34, 53, 65], allowing activists, policymakers, and researchers to examine a range of policing behavior, including stops,searches, and arrests. However, there is still one type of data that remains largely un-available to the public within the United States: information on where the police are deployed in the first place. This data is crucial for several reasons. First, statistical analyses of police deployments have revealed inefficiencies or inequities [49, 50] in which some areas have disproportionate police deployments. Second, disparities in police deployments create biases in downstream outcomes like arrests. If an area has a heavier police presence, crimes are more likely to result in arrests. Thus, more heavily policed neighborhoods may appear to be more prone to crime, when they are simply more prone to observed crime; similarly, residents of these neighborhoods may appear to be more likely to commit a crime, when in fact they are simply more likely to be arrested for it. This bias has been observed in practice: for example, African Americans are far more likely to be arrested for marijuana use than are white Americans, even though surveys of drug use do not show the same racial disparities [57]. This bias could also propagate into algorithms used in policing and criminal justice — including pretrial risk assessments [15, 16, 42]and predictive policing algorithms [20, 45, 54, 58, 62] — since these algorithms can use arrests, or outcomes downstream from arrest slike convictions, as input.Deployment data are thus essential for monitoring disparities or inefficiencies in policing and detecting potential biases in al-gorithms. Even aggregated deployment data — grouped by neigh-borhood or demographic — would be useful towards this end. In Spite of this, police deployment data remains largely unavailable to the public within the United States. Addressing this need, we introduce a novel methodology for monitoring police deployments: detecting police vehicles in dashcam images of public street scenes. Using a dataset of more than 24 million dashcam images collected throughout New York City in 2020, we annotate a training dataset of 9,449 images for presence of police vehicles, and train a deep learning model to identify police vehicles with high accuracy (av-erage precision 0.82; AUC 0.99). We use this model to identify 233,596 dashcam images which contain police vehicles. We develop a framework for analyzing inequality in police deployment levels across neighborhoods — that is, the probability an image within a given neighborhood contains a police vehicle — which compensates for several data and model biases. Our analysis reveals substantial disparities in police deployments: the neighborhood with the highest police deployments has almost 20 times higher deployments than the neighborhood with lowest deployments. Two very dif-ferent types of areas experience high police deployments: dense,high-income, commercial areas; and areas with higher proportion of Black and Hispanic residents and lower incomes. We discuss the implications of these disparities for policing and algorithmic equity. We also discuss the residual potential biases in the data which cannot be removed by our extensive debiasing pipeline, and argue that this fact suggests that the police should simply release more reliable and straightforward aggregated deployment data. [...] Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020. Each image is 1280 x 720pixels. We remove a small number of duplicate images (less than 0.01% of the overall dataset) with identical latitudes, longitudes,and timestamps. ","534-5, 536","Our dataset is provided by Nexar, a company which provides ride-sharing (Uber, Lyft, NYC Taxi, etc) drivers with dashboard cameras(dash cams) to record their drives (which can be useful if, for exam-ple, an accident occurs). The dataset consists of 24,803,854 images taken throughout the five boroughs of New York City betweenMarch 4 2020 and November 15 2020."
