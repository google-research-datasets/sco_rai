,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{nannini2023explainabilityinai,
    author = {Luca Nannini and Agathe Balayn and Adam Leon Smith},
    title = {Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-08, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,EuropeanComission,Agent,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,European Commission,
10,AIGovernance,Perceived_Problem,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,AI governance that balances promoting innovation with protecting citizens’ rights and safety,
11,AICommunication,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,Communication on Artificial Intelligence for Europe,
12,EUStrategy,Strategy,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,European strategy for its development and deployment,
13,Transparency,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,transparency,
14,Accountability,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,accountability,
15,HumanOversight,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,human oversight,
16,Trust,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,principle of trust,
17,MitigatingBias,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,mitigating bias,
18,OtherRisk,Perceived_Problem,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,other risks,
19,RightToExplanation,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,“right to an explanation”,
20,GDPR,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,EU General Data Protection Regulation,
21,Article22AndRecital71,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,Article 22 and Recital 71,
22,RightToNoAutomatedDecision,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,right not to be subject to a decision based solely on automated processing,
23,Article15H,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,Art. 15(1)(h),
24,MeaningfulInformation,Perceived_Need,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,“meaningful” information,
25,Individual,Agent,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,the individual,
26,Experts,Agent,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,experts,
27,ArgumentForTransparency,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,arguing that it provides a framework for ensuring transparency and explainability of automated decision-making,
28,CriticismForVagueness,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,criticized it for being too vague and difficult to implement in practice,
29,WhitePaper,Artifact,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,White Paper on Artificial Intelligence,
30, , , , , ,
31,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
32,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
33,EuropeanComission,hasProducedArtifact,AICommunication,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe
34,EuropeanComission,hasProducedArtifact,WhitePaper,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,the Commission published the White Paper on Artificial Intelligence
35,Experts,hasProducedArtifact,CriticismForVagueness,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice"
36,Experts,hasProducedArtifact,ArgumentForTransparency,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making"
37,AIGovernance,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety."
38,EUStrategy,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment"
39,Transparency,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,The Communication states that the EU’s approach to AI regulation is based on the principles of transparency
40,Accountability,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability,"
41,HumanOversight,constrainsAgent,Individual,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight."
42,Trust,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust"
43,MitigatingBias,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias"
44,OtherRisk,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks,"
45,RightToExplanation,constrainsAgent,EuropeanComission,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR)
46,AICommunication,reflectsPrecept,AIGovernance,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety."
47,AICommunication,reflectsPrecept,EUStrategy,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment"
48,AICommunication,reflectsPrecept,Transparency,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,The Communication states that the EU’s approach to AI regulation is based on the principles of transparency
49,AICommunication,reflectsPrecept,HumanOversight,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability,"
50,AICommunication,reflectsPrecept,Accountability,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight."
51,AICommunication,reflectsPrecept,Trust,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust"
52,AICommunication,reflectsPrecept,MitigatingBias,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias"
53,AICommunication,reflectsPrecept,OtherRisk,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks,"
54,GDPR,reflectsPrecept,RightToExplanation,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR)
55,Article22AndRecital71,reflectsPrecept,RightToNoAutomatedDecision,"In 2018, the European Commission (EC) acknowledged the potential of AI to drive economic growth and competitiveness through the Communication on Artificial Intelligence for Europe [33], outlining the first European strategy for its development and deployment.The document details a comprehensive approach to AI governance that balances promoting innovation with protecting citizens’ rights and safety. The Communication states that the EU’s approach to AI regulation is based on the principles of transparency, accountability, and human oversight. Regarding transparency, the document approaches explainability as a high-level AI desiderata. The theme is mentioned under the principle of trust, increasing transparency, and mitigating bias and other risks, in a wider ethical and legal framework for AI development. The first major discussion on the legitimacy of explanations over algorithmic decision-making systems, including AI ones, was found in the presumption of a “right to an explanation” within the EU General Data Protection Regulation (GDPR) [51] that came in force in 2018. The GDPR includes provisions for data subjects’ rights such as accessing personal data and having them rectified in relation to automated decision-making. 2. This is in conjunction to Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing, including profiling, if it produces legal or similarly significantly effects on them. Art. 15(1)(h) emphasizes the importance of ensuring that individuals have “meaningful” information about the logic involved in the decision-making process alongside “envisaged consequences” of such processing for the individual. The provisions have been subject of an intense debate among experts, with some arguing that it provides a framework for ensuring transparency and explainability of automated decision-making [22, 94], while others have criticized it for being too vague and difficult to implement in practice [141].To notice, the phrasing of articles reduces severely the casuistry of its enforcement, not setting a baseline over typology and sufficiency of explanations, thus leaning towards an illusion of remedy rather than a burden of proof for legal recourse [45, 46]. As a final note, in 2020 the Commission published the White Paper on Artificial Intelligence [34]. The document yet represents the first structural communication for an European strategy in AI to foster R&D competitiveness.",1200-1,"Article 22 and Recital 71, which state that individuals have the right not to be subject to a decision based solely on automated processing"
