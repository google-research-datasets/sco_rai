,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{nannini2023explainabilityinai,
    author = {Luca Nannini and Agathe Balayn and Adam Leon Smith},
    title = {Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-08, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,UKGov,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the UK government [...] cabinet office,
10,RandDStrategy,Strategy,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,public AI R&D strategy to enhance its market competitiveness ,
11,AISectorDeal,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,in parallel to an AI Sector Deal [...] The Deal,
12,ATI,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Alan Turing Institute,
13,ICO,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Information Commissioners Office,
14,GuidanceForExplaining,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,guidance in explaining AI decisions,
15,ExplainingDecisionsWithAI,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,a well-structured report named Explaining Decisions with AI,
16,AIAuditingFrameworks,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,reports on AI auditing frameworks,
17,AIDataProtection,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,AI data protection,
18,NovelApproachWidening,Strategy,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"novel approach to widening participation in AI standards,",
19,NPL,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the National Physics Laboratory (NPL),
20,BSI,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,British Standards Institute (BSI).,
21,CDDO,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the Central Digital & Data Office (CDDO),
22,OAI,Agent,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Office of Artificial Intelligence,
23,GuidanceOnEthics,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"a guidance on ethics, transparency, and accountability of ADM systems",
24,TransparencyHub,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,a cross-government standard hub for algorithmic transparency,
25,FutureStandards,Perceived_Problem,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,future standards in its AI innovation strategies,
26,TransparencyStandard,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the first algorithmic transparency standard,
27,CenterForDataEthics,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Centre for Data Ethics and Innovation (CDEI),
28,NationalDataStrategy,Artifact,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,a National Data Strategy,
29, , , , , ,
30,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
31,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
32,UKGov,hasProducedArtifact,CenterForDataEthics,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the UK government established the Centre for Data Ethics and Innovation (CDEI)
33,UKGov,hasProducedArtifact,NationalDataStrategy,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the UK released a National Data Strategy
34,UKGov,hasProducedArtifact,AISectorDeal,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal."
35,AISectorDeal,reflectsPrecept,RandDStrategy,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures.
36,ATI,hasProducedArtifact,GuidanceForExplaining,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Alan Turing Institute and Information Commissioners Office for guidance in explaining AI decisions
37,ATI,hasProducedArtifact,ExplainingDecisionsWithAI,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI"
38,ICO,hasProducedArtifact,GuidanceForExplaining,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,Alan Turing Institute and Information Commissioners Office for guidance in explaining AI decisions
39,ICO,hasProducedArtifact,ExplainingDecisionsWithAI,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI"
40,ICO,hasProducedArtifact,AIAuditingFrameworks,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"In that particularly prolific year for the ICO, it also released reports on AI auditing frameworks [111] and AI data protection [110]"
41,ICO,hasProducedArtifact,AIDataProtection,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"In that particularly prolific year for the ICO, it also released reports on AI auditing frameworks [111] and AI data protection [110]"
42,NovelApproachWidening,constrainsAgent,UKGov,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"The UK is also taking a novel approach to widening participation in AI standards,"
43,NovelApproachWidening,constrainsAgent,ATI,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute,"
44,NovelApproachWidening,constrainsAgent,NPL,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL),"
45,NovelApproachWidening,constrainsAgent,BSI,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI)."
46,CDDO,hasProducedArtifact,GuidanceOnEthics,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO),"
47,UKGov,hasProducedArtifact,GuidanceOnEthics,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice,"
48,OAI,hasProducedArtifact,GuidanceOnEthics,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence"
49,CDDO,hasProducedArtifact,TransparencyHub,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021"
50,UKGov,hasProducedArtifact,TransparencyHub,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021"
51,OAI,hasProducedArtifact,TransparencyHub,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,"To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021"
52,FutureStandards,constrainsAgent,UKGov,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,the UK plans to integrate future standards in its AI innovation strategies
53,ATI,hasProducedArtifact,TransparencyStandard,"During the implementation period of Brexit, in 2018 the UK government established the Centre for Data Ethics and Innovation (CDEI), the first governmental body worldwide to advise on the ethical and societal implications of AI and data-driven technologies. In 2019, the UK released a National Data Strategy [57] advocating for the adoption and use of safe and explainable data sources, in parallel to an AI Sector Deal [58]. The Deal outlined a public AI R&D strategy to enhance its market competitiveness while reinforcing digital in-frastructures. In the plan, it was announced the intention to set up a research collaboration between the Alan Turing Institute (ATI) and the Information Commissioners Office (ICO) for guidance in explaining AI decisions. In 2020, that guidance was released in a well-structured report named Explaining Decisions with AI [75]. In that particularly prolific year for the ICO, it also released reportson AI auditing frameworks [111] and AI data protection [110]. The guidance on explainability is the first comprehensive governmental technical report ever produced detailing AI explainability definition,methods, process, and impacts. The document is structured in three parts, respectively addressed to compliance teams, technical teams,and management. This reflects the priority given by ICO & ATI to provide industry guidance on explainable AI. Yet, their major contribution is to be found in the establishment in 2019 of ProjectExplAIn [74], the first engagement strategy on AI explainability for organizations, implementing the guidance through workbooks and workshops. Leading AI industry standards. The UK is also taking a novel approach to widening participation in AI standards, led by the AlanTuring Institute, the National Physics Laboratory (NPL), and the British Standards Institute (BSI). To notice, in May 2021 a guidance on ethics, transparency, and accountability of ADM systems was released by the Central Digital & Data Office (CDDO), the CabinetOffice, and the Office of Artificial Intelligence [115]. Their major output is the development of a cross-government standard hub for algorithmic transparency for government departments and public sector bodies (Pillar 3 of the National Strategy Plan) [60] announced in November 2021 [29]. Informed by its close collaborations within AI standardization bodies in the EU and worldwide, the UK plans to integrate future standards in its AI innovation strategies [59, 60]. This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute[7] in July 2022, calling for a coordinated approach to increaseAI readiness and proposing the creation of an AI and RegulationCommon Capacity Hub to facilitate regulatory collaborations for policymakers.",1203,This direction found output in the first algorithmic transparency standard for government departments and public sectors in Novem-ber 2021 [29] alongside a report from The Alan Turing Institute
