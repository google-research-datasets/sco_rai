,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{golpayegani2023, author = {Golpayegani, Delaram and Pandit, Harshvardhan J. and Lewis, Dave}, title = {To Be High-Risk, or Not To Be—Semantic Specifications and Implications of the AI Act’s High-Risk AI Applications and Harmonised Standards}, year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,EuopeanComission,Agent,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,the European Commission,
10,AIAct,Artifact,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,the AI Act,
11,NeedForCompliance,Perceived_Problem,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,can achieve compliance with the requirements,
12,HarmonizedStandards,Strategy,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,through conformance to harmonized standards,
13,GuardAgainstHarm,Perceived_Need,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,to guard individuals in the European Union against AI-related harm,
14,RiskBasedStructure,Strategy,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,"risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental impacts on health, safety, and fundamental rights.",
15,AIProviders,Agent,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,AI providers ,
16, , , , , ,
17, , , , , ,
18,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
19,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
20,EuopeanComission,hasProducedArtifact,AIAct,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,the AI Act was first proposed by the European Commission in April 2021
21,AIAct,reflectsPrecept,GuardAgainstHarm,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harm
22,AIAct,reflectsPrecept,RiskBasedStructure,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,"The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental impacts on health, safety, and fundamental rights."
23,NeedForCompliance,constrainsAgent,AIProviders,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,AI providers can achieve compliance with the requirements
24,HarmonizedStandards,constrainsAgent,AIProviders,"Legislation Development Process: Following the ordinary leg-islative process1, the AI Act was first proposed by the European Commission in April 2021 as a binding instrument to guard individuals in the European Union against AI-related harms. Theproposal has to be approved by both the European Parliament and the Council of the European Union to be passed as EU legislation.At the end of its term in June 2022, the French presidency of theCouncil published a consolidated version3. The Council’s common position, the latest draft of the Act at the time of writing, was issued in November 2022 by the Czech presidency. During the first reading of the Act in the European parliament, more than 3000 amendments were tabled by the responsible committees, namely the Committee On the Internal Market and the Committees on Consumer Protec-tion and Civil Liberties, Justice and Home Affairs. Finalization of the Parliament’s position, which is expected in the first semester of 2023, will allow entering the trilogue phase, whereby the Commission, Parliament, and Council negotiate the AI Act behind closed doors to reach an agreement on the final text. 12 days after the publication of the Act in the Official Journal of the European Union, it will come into force (Art. 85(1)) and 36 months after, it will be applied (Art. 85(2)). In this paper, we adopt the Council's Common position on the AI Act.Structure and Content: The AI Act’s key feature is its risk-based structure where different legal regimes are established for governing AI systems according to their potential detrimental im-pacts on health, safety, and fundamental rights. These legal regimes cover four clusters of AI systems with (i) unacceptable (severe), (ii)high, (iii) limited, and (iv) minimal risks. Rather than providing a comprehensive overview of the Act’s content, we focus on the high-risk regime (described in Title III), which follows the new legislative framework (NLF)—a common EU product-related legal framework adopted in 2008. According to Art. 6, an AI system classifies as high-risk if it is: (1) a product which requires third-party conformity assessment under at least one of the Union harmonisation legislations listed in Annex II; (2) used as a safety component of a product mentioned in the preceding point; or (3) used in these-cases described in Annex III. Chapter 2 of Title III prescribes the essential requirements that a high-risk AI system should fulfill,including having a risk management system in place (Art. 9) and being accompanied by technical documentation (Art. 11). Legal Provisions applied to high-risk AI providers, users, and other related actors such as importers and distributors are described inChapter 3. Following the NLF, the Act introduces harmonized standards as instruments for providing detailed technical solutions for compliance with essential requirements. Owing to the presumption of conformity (Art. 40), AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation [24].",609,"AI providers can achieve compliance with the requirements through conformance to harmonized standards, without undergoing the costly and time-consuming process of requirements interpretation"
