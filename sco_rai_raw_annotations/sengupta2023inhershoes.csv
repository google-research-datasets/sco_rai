,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{sengupta2023inhershoes,
    author = {Nandana Sengupta and Ashwini Vaidya and James Evans},
    title = {In her Shoes: Gendered Labelling in Crowdsourced Safety Perceptions Data from India},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-09, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,Participants,Agent,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi,
10,DataDistribution,Artifact,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,distribution of the underlying (and observed) training data,
11,SafetyRatings,Artifact,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,safety perceptions ratings ,
12,SafetyPerceptions,Causal_Theory,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,predictions of safety perceptions,
13,GenderDifferences,Perceived_Problem,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,significant gender differences in individual ratings,
14, , , , , ,
15, , , , , ,
16, , , , , ,
17, , , , , ,
18, , , , , ,
19, , , , , ,
20, , , , , ,
21, , , , , ,
22, , , , , ,
23,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
24,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
25,Participants,hasProducedArtifact,SafetyRatings,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,"safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi"
26,DataDistribution,influencesPrecept,SafetyPerceptions,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data
27,SafetyRatings,reflectsPrecept,GenderDifferences,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions [...] significant gender differences in individual ratings
28,GenderDifferences,constrainsAgent,Participants,"Our methodology consists of obtaining safety perceptions ratings and related data from respondents on a fixed set of previously collected street views from Delhi, India. Participants in the survey consist of undergraduate and postgraduate students at a reputed engineering institute in New Delhi. Using the primary data thus collected, consisting of 11, 200 safety perception ratings data from 224 respondents over 50 street views each, we run extensive simulation experiments where varying proportions of labels from each gender are assumed missing. We compare predictive abilities of standard matrix factorization models from the ML literature and demonstrate that predictions of safety perceptions depend crucially on the distribution of the underlying (and observed) training data. We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety. Overall our findings demonstrate the pitfalls of using crowdsourced data from mobile applications as an input to public policy as also empirical academic research.Our findings have particularly important implications for public policy, especially given the increasing incorporation of crowd-sourced data and algorithms into public policy processes [24]. Wedemonstrate that there is an urgent need to analyse potential bias in crowdsourced data [10], particularly from the perspective of the Global South, which has received woefully less attention in the scientific discourse around algorithmic fairness [25]. This becomes crucial in economies such as India where access to Information and Communication Technologies (ICTs) is highly skewed towards the male population [1]. ",184,"We find that obtaining large amounts of crowdsourced labels from male respondents has limited utility for predicting female safety perceptions and in certain situations more labels from male respondents reduces prediction accuracy for females. We also find significant gender differences in individual ratings (which are exacerbated for night-time images), response times and vocabularies used to describe visual safety."
