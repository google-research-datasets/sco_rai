,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation, ,"{poulain2023improvingfairness,
    author = {Raphael Poulain and Mirza Farhan Bin Tarek and Rahmatollah Beheshti},
    title = {Improving Fairness in AI Models on Electronic Health Records: The Case for Federated Learning Methods},
    year = 2023
}", , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-09, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,PreservingFairness,Goal,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare.",
10,PossibleBias,Perceived_Problem,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,the possible biases,
11,FederatedLearningParadigm,Artifact,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,a federated learning paradigm (FL; which is a popular choice in healthcare settings),
12,Researchers,Agent,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,we,
13,Patients,Agent,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA",
14,AIModels,Agent,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,AI models’,
15,MIMIC-III,Artifact,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"MIMIC-III [21], the most popular real-world EHR dataset",
16, , , , , ,
17,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
18,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
19,PreservingFairness,constrainsAgent,Developers,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare."
20,PossibleBias,constrainsAgent,AIModels,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,AI models’ overall prediction performance is often prioritized over the possible biases such models could have.
21,FederatedLearningParadigm,influencesPrecept,PossibleBias,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings)
22,Researchers,hasProducedArtifact,FederatedLearningParadigm,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used."
23,Patients,hasProducedArtifact,MIMIC-III,"Developing AI tools that preserve fairness is of critical importance, specifically in high-stakes applications such as those in healthcare. However, health AI models’ overall prediction performance is often prioritized over the possible biases such models could have. In this study, we show one possible approach to mitigate bias concerns by having healthcare institutions collaborate through a federated learning paradigm (FL; which is a popular choice in healthcare settings). While FL methods with an emphasis on fairness have been previously proposed, their underlying model and local implementation techniques, as well as their possible applications to the healthcare domain remain widely under investigated. Therefore, we propose a comprehensive FL approach with adversarial debiasing and a fair aggregation method, suitable to various fairnessmetrics, in the healthcare domain where electronic health records are used. Not only our approach explicitly mitigates bias as part of the optimization process, but an FL-based paradigm would also implicitly help with addressing data imbalance and increasing the data size, offering a practical solution for healthcare applications.We empirically demonstrate our method’s superior performance on multiple experiments simulating large-scale real-world scenar-ios and compare it to several baselines. Our method has achieved promising fairness performance with the lowest impact on overall discrimination performance (accuracy). [...] Throughout our experiments, we evaluated our method on four cohorts from two different datasets. Specifically, we have used,1) the Synthia dataset [46], a public synthetic EHR simulation program that we have used to generate two cohorts of patients from different US states, and 2) MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA to generate two cohorts, one IID (independent and identically distributed) and one non-IID. ",1599-1601,"MIMIC-III [21], the most popular real-world EHR dataset of patients admitted to the Intensive CareUnit (ICU) from the Beth Israel Deaconess Medical Center in Boston,USA"
