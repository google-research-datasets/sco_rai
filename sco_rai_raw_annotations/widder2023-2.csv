,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{widder2023, author = {Widder, David Gray and Zhen, Derrick and Dabbish, Laura and Herbsleb, James},
title = {It’s about Power: What Ethical Concerns Do Software Engineers Have, and What Do They (Feel They Can) Do about Them?},
year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,SoftwareEngineers,Agent,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,SOFTWARE ENGINEERS [...] practitioners,
10,EthicalConcerns,Perceived_Problem,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,ETHICAL CONCERNS,
11,ResourceConstraints,Perceived_Problem,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,resource constraints,
12,PhrasingInBusinessTerms,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success.",
13,CapturingHeartsAndMinds,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,“entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds,
14,PurposefullyPoorImplementation,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,“I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting”,
15,MilitaryUseExemption,Artifact,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,nobody has to take part in any software projects involving military use.,
16,Ultimatums,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns.",
17,Resignation,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,Resignation,
18,RefusingEmploymentOffer,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,refusing offers of employment.,
19,AversionToGamblingWork,Perceived_Problem,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,don’t like to work for a company that does business in gambling.,
20,EthicalResponsibility,Perceived_Need,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,we have a responsibility to be stick in the mud about ethics.,
21,CollectiveBargaining,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,Collective bargaining and tech worker boycotts,
22,AppealToLawEnforcement,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option",
23,CopyLeft,Strategy,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"opted to use a “copyleft” (i.e., [70]) license in order to limit downstream harms of OS agricultural soft-ware they created",
24,Cynicism,Perceived_Problem,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ]just so that it would be easier tocut and run, if somebody asked me to do something unethical.” ",
25,CommunityInEthicalAI,Goal,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,Finding community in the ethical AI space made me feel so much more grounded,
26,TechncialSolutionsToMitigateHarms,Artifact,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms.,
27,AffordanceToMinimizePrivacyConcerns,Artifact,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,came up with a design affordance to minimize the privacy concern he had about employee location tracking,
28,Company,Agent,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,the company,
29, , , , , ,
30,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
31,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
32,EthicalConcerns,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,SOFTWARE ENGINEERS ETHICAL CONCERNS
33,SoftwareEngineers,hasProducedArtifact,TechncialSolutionsToMitigateHarms,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms.
34,SoftwareEngineers,hasProducedArtifact,AffordanceToMinimizePrivacyConcerns,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking
35,ResourceConstraints,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,his geofencing solution was ultimately rejected due to resource constraints
36,PhrasingInBusinessTerms,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success."
37,CapturingHeartsAndMinds,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds"
38,PurposefullyPoorImplementation,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting”
39,Company,hasProducedArtifact,MilitaryUseExemption,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,“We had a policy at the company that nobody has to take part in any software projects involving military use.”
40,Ultimatums,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns."
41,Resignation,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet"
42,RefusingEmploymentOffer,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,The Most common action reported in this category was refusing offers of employment.
43,AversionToGamblingWork,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,I don’t like to work for a company that does business in gambling.
44,EthicalResponsibility,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics.
45,CollectiveBargaining,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with"
46,AppealToLawEnforcement,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option"
47,CopyLeft,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"one practitioner personally opted to use a “copyleft” (i.e., [70]) license in order to limit downstream harms of OS agricultural soft-ware they created"
48,Cynicism,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,"And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ]just so that it would be easier tocut and run, if somebody asked me to do something unethical.” "
49,CommunityInEthicalAI,constrainsAgent,SoftwareEngineers,"4 RQ2: WHAT HAPPENS WHEN SOFTWARE ENGINEERS DEVELOP ETHICAL CONCERNS?4.1 Technical Solutions Some practitioners proposed technical solutions — changes in the functionality or design of a system through code modifications —in an attempt to mitigate potential harms. Technical solutions work best on Bug and Feature-scoped concerns, because harms resulting from the core purpose of a product or the business practices of an organization (i.e., those later in Sec. 3.2) are not able to be resolved through changes to system implementation. Furthermore, even when practitioners see opportunities for tech-nical solutions, their actual implementation depends on manage-ment agreeing that perceived harms are important enough to war-rant dedicating resources to fix them. For example, both intervie-wees I6 and I10 (whose concerns were summarized in 3.2) came up with technical solutions that would have resolved their concerns,which were dismissed by management. Interviewee I6 came up with a design affordance to minimize the privacy concern he had about employee location tracking: “if you really desperately wanted to [...] see where each person is on site, [...] we could geofence thesite [...] If they’re not in [the site], the tracking is off.” (I6). While management was sympathetic to his privacy concerns – “[my man-ager] agreed [...] we cannot monitor people’s comings and goings” (I6), his geofencing solution was ultimately rejected due to resource constraints: “he blatantly told me that’s too much work. And he's not signing off on that.” (I6). Interviewee I10 proposed a solution to avoid erroneously denying people insurance coverage due to GPS rounding errors, suggesting “we [could] have a three value response[the third being] ‘maybe need to check further if it was right on the boundary”’ (I10). However, what the practitioner had experienced a serious concern “people need flood insurance for their houses [...]I had been victim to flooding and lost a bunch of my stuff” (I10) was a non-issue for the client: “the client cut me off and told me she didn't care and that [...] I just needed to do it.” (I10) He was later “dressed [...]down for speaking out of turn with the client” (I10), and the manager “threatened to fire me if I didn’t do the work.” (I10)4.2 Negotiating within organizational incentives Practitioners also sought to resolve ethical concerns by convincing decision-makers like engineering or product managers that harms are serious enough to warrant action. Often times, this involves phrasing ethical concerns in terms of their effects on organizational incentives such as profit or product success. For example, one ML researcher concerned about his projects use of facial identification (i.e., who is in this picture?) reported successfully pivoting the direction of his project to facial verification(i.e., are these two pictures the same person?). He raised ethical concerns about downstream uses like bias and surveillance to his management, but couched these within organizational incentives to pursue an easier and more achievable project (verification) instead of a more difficult one (identification): “because we were understaffed[I said] ‘ [...] we don’t have the resources to do it.”’ (I14) Another interviewee, who had ethical concerns about improper employer vetting in a job matching application he helped develop, described attempting to get senior management to shutter the project by appealing to the organization’s core values. “[I said] we either need to invest more money into understanding what is going on here [...]or we need to pump the brakes [...] I was quoting, you know, our organization's code of ethics and stuff like that.” (I9) The likelihood of ethics negotiations succeeding are, as one practitioner puts it, “entirely [dependent] on the organization and your ability to talk to people and [...] capture hearts and minds.” (I2)A practitioner’s ability to affect change internally through “rocking the boat” relates to the broader work Debra Meyerson has done on “tempered radicals” [45] — leaders who leverage their status within organizations to promote their own values and ideals. The Approach of affecting change from atop the corporate ladder was also suggested by one of our interviewees: “[you could] work your way into a leadership position, and then start making different kinds of ideas” (I5). However, they acknowledged the fraught existence of individuals attempting both conformity and rebellion: “you’d have to both hold on to your ideals [...] And at the same time, be willing to compromise your ideals quite heavily in order to work your way into a leadership position in the first place.” (I5)4.3 RefusalOne common action respondents reported was refusing to work on the task they found unethical. Refusals took on various forms, the first being “quiet quitting” – reducing one’s productivity. One practitioner who was asked to build a system to bypass spam filters wrote: “I purposefully created a poor implementation and did not dedicate very much energy to make a working solution.” (S49). An-other respondent wrote that they “pretended to complete the task but didn't” (S62). We found that the tactic of “quiet quitting” emerged from a feeling of powerlessness to affect change within organiza-tions, and as a result is often accompanied by searching for other jobs (see 4.4). One practitioner who reported reducing productivity felt that it was impossible to resolve their concerns internally, since the product they were concerned about was already in production:“I don’t think I had any power in this dynamic because [the product]was already deployed. This was just like a minor upgrades [to] make it more usable.” (I13) Since the practitioner saw little utility in pursu-ing a resolution internally, they “reduced productivity to a minimum and found another job” (S6). A handful of respondents reported seeking reassignment to different project. These practitioners removed themselves personally from the concerning project, but did not attempt to use their leverage to shut the project down: “I was given another project to work on. I didn’t kill the project, but I also didn’t contribute to it.”(S19). Reassignment is typically only possible at organizations with many product lines or clients, and practitioners felt they needed seniority to ask for reassignment, as one described: “My seniority and wide swathe of other projects to choose from” (S19) made securing a reassignment easier. One participant described a policy to make it easy to seek reassignment on ethical grounds: “We had a policy at the company that nobody has to take part in any software projects involving military use.” (S95) Other practitioners delivered ultimatums to management – putting their job on the line and making it clear that they would quit unless their concern was addressed, with mixed results dependent on their leverage and the scope of their concerns. One practitioner working on hospital software was concerned that the rushed rollout of an update would jeopardize patient outcomes. In response, he raised the concern to management forcefully: “I looked that manager in the eye and I said: you are going to have to write me up or fire me, but I’m not doing it. I’m not going to put patients’ lives at risk, because you've got a pile of money sitting on the table.” (I12). This confrontation resulted in management stepping back and reassessing the necessity of the update. One participant suggested that ultimatums can be a wake up call for management, forcing them to take seriously harms they may have ignored in the past: “maybe [leadership] didn't know how the individuals in the org felt. And then, individuals in the org might raise a stink. And sometimes that leads to some work being paused or just like not being done.” (I7) However, they suggest that the effectiveness of an ultimatum is highly dependent on how much leverage a practitioner has, and that collective ultimatums tend to be more effective: “if it looks like we’re gonna lose a big chunk of employees, [management] might say, we can’t afford that [...] it kind of depends on the individual, whether you have leverage over leadership.” (I7).Resignation is typically a last resort: practitioners resign after their technical solutions or compromises are rejected (I6, I10); when escalations go sour: “he threatened to fire me if I didn’t do the work.And that’s when I decided I would just quit.” (I10); or when they lose faith that the ethical concern can be resolved internally: “Raised Concerns with executives. Started ethics discussion group among em-ployees. Left the company after seeing no progress.” (S53). Resignation Allowed participants to put distance between themselves and the projects they deemed harmful, but they often reported this as bitter-sweet: in resigning, they relinquish control over development of the harmful system, as another developer is often hired on and progress resumes. One survey respondent lamented this, saying his concerns were not resolved because “the company hired someone else. [...] I Felt that I would have been in a better position ethically if I had taken the contract and had done a bad job of it.” (S79) However, in some cases, the resignation of a crucial developer in an already precarious project can terminate the project. One participant reasoned that their departure likely doomed the project: “I was also the only one who had any serious level of software development competence [...]they generally struggled with deploying the existing models [...] so I Can't imagine that they would have deployed it.” (I5) In another in-stance, a contract worker heard that his client canceled the project he worked on after his resignation, reflecting: “[... quitting] can give the client cold feet on the project, it makes it look like the consulting firm is incapable of managing the project. So [...] they’re likely to just cancel the project completely.” (I6)4.4 Feet voting: “This work doesn’t get done without us” The strategy of “feet voting” describes the proactive actions practi-tioners took to align their employment decisions with their ethical views (such as career planning), in contrast to actively refusing assignments or quitting jobs due to an unresolved concern. The Most common action reported in this category was refusing offers of employment. Either turning down a job offer: “I rejected the offer” (S47), dropping out of the interview pipeline: “I decided to not continue interviewing with said job” (S45), or deciding not to apply to a position: “Ignore the job advert” (S82). Many saw turning down employment to be easier than resigning, but others lamented passing up lucrative jobs: “[Anything that made it feel harder to act?] Just the big bag of money.” (I17) or interesting projects: “I love game development, but I don’t like to work for a company that does business in gambling.” (I150) Some practitioners with concerns about their previous industries raison d’être went to great lengths to transition to another industry.But past experience makes this difficult, as one participant trying to transition away from developing war-fighting simulations said:“It’s difficult because my experience in this industry makes me most attractive to other companies working in the same industry.” (S88)A different practitioner found it necessary to move to an entirelydifferent state to find opportunities he was ethically aligned with:“I realized, well, if I’m going to stay in this area, like the odds of me atsome point, working [...] on defense contracts are pretty high. [...] I’mbeing kind of a picky applicant on what companies I’ll work for. Andif I really want to do that, then I might have to consider moving [...]”(I1) He also described being more intentional in screening potentiale mployers for red flags: “I realized you really have to look at like the ethics of the corporation, like, as part of your interviewing process[for example, in the interview] I just asked about the details of theproject [...] what space they were in, what type of product they were selling, that sort of thing.” (I1)One practitioner argued that the favorable software engineering job market implies a unique ethical responsibility: “Even like the2008 financial crash [...] every software developer I knew still had work. Even if the job they had disappeared, they had a new one within a week or two. [...] I think software development is incredibly resilient against recession [...] that’s why we have a responsibility to be stick in the mud about ethics. This work doesn’t get done without without us.” (I10) However, not all participants felt this way, and we discuss feelings of precarity in section 5.1.Collective bargaining and tech worker boycotts are instances of feet voting at scale, in which practitioners collectively withhold labor from organizations they had ethical concerns with. These Tactics have grown in prominence at large tech firms [37]. However,among the practitioners in our study, only one interviewee raised this “the company would have to be pushed and that’d have to be either externally through [...] legislation or similar tools, or just public opprobrium or internally through unionization” (I5), mentioning that “I did attempt to do a bit of [union] organizing work. But unfortunately,I was doing that alone.” (I5)4.5 Leveraging legal systemsOne practitioner we spoke to attempted to collect information to raise his concern with law enforcement but did not ultimately go through with it: “I knew [...] they were going to have to start skirting rules right from the start. So, so yeah, I asked for all of the requirements,documents, anything you could give me to help me understand how to build such a system [...] My intention was just to walk into the FBI.”(I17) Another interviewee echoed this idea, saying that for harms that call into question the raison d’être of the entire organization(see Section 5.3), external enforcement was the sole option: “if you have a concern, you should take it up with the legislators of the courts.” (I2)Practitioners who maintain open source software can also lever-age laws around software licensing to prevent misuse. For instance,one practitioner personally opted to use a “copyleft” (i.e., [70])license in order to limit downstream harms of OS agricultural soft-ware they created, but conceded that it was unlikely that they would have the resources for costly litigation to enforce them. In Discussing the efficacy of their action, they compared the process of choosing a license to what they saw as the small and easy yet important effect of voting as a way to effect change: “it’s a small,little one time thing you can do, that probably won’t help you. But,but if it does help you, it is huge. And it only took two minutes of your time to set in place, and it’s there for years, you know, that you may need to fall back on that if that’s your only line of defense.” (I19)4.6 The psychological toll of raising concernsPractitioners reported experiencing anxiety, depression and iso-lation throughout the process of identifying and raising ethical concerns. The process of raising ethical concerns to an employer was stressful, especially for full-time employees, for whom their organizations are their sole benefactors. One practitioner writes: “it terrifies me to confront an ‘authority’ figure, especially one who was the source of my financial well-being.” (S62) Another practitioner described raising ethical concerns with a client as: “one of the most terrifying moments in my life.” (I10) The aftermath of a failed es-calation can also seriously affect practitioners’ mental health, as one interviewee recalled: “I spent a good few weeks lying in my bed[with] serious depression [...] I didn’t want to leave my apartment [...I] just couldn’t face [...] checking work emails.” (I5) After his concerns were dismissed by both the client and his direct manager, another described “It gave me a lot of anxiety and depression. [...] And it kinda made me cynical [... I] approached most new working situations[...] trying to not get too involved [... ] just so that it would be easier tocut and run, if somebody asked me to do something unethical.” (I10)Practitioners also reported that just having an ethical concern tall was distressing. One interviewee quit multiple jobs over ethical concerns, recounting “I was so distraught over what I was being asked to do, I threw up in the parking lot before going into work.” (I10)Another interviewee spoke about the alienating effect of being the only person in the office with an ethical concern: “[I felt] kind of like an outcast” (I1), and another survey respondent suggested that raising concerns could lead to hostility: “I do not want to judge, or be judged, by colleagues for my views. Without care, such discussions can lead to a hostile work environment.” (S38) However, others circulation concerns among peers in order to feel less isolated in their concerns.One interviewee leveraged their organization’s employee directory and intranet to “find other people who cared about the same things”(I4) and start ethics reading and discussion groups. Looking back, they reflected: “Finding community in the ethical AI space made me feel so much more grounded.” (S14). ",470-2,they reflected: “Finding community in the ethical AI space made me feel so much more grounded
