,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{wu2023theslowviolence,
    author = {Yuxi Wu and Sydney Bice and W. Keith Edwards and Sauvik Das},
    title = {The Slow Violence of Surveillance Capitalism: How Online Behavioral Advertising Harms People},
    year = 2023
}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-19, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,HarmsFromOnlineBehavioralAdvertising,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,having been harmed by OBA,
10,UnsettledByTargetedAds,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,feeling unsettled by or uncomfortable with the specificity of targeted ads.,
11,DesireForExplanationsForTargeting,Perceived_Need,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. ,
12,BrowingMistakeRegret,Causal_Theory,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,expressed regret about mistakes they had made along the way when researching and discussing the related ad topics,
13,TargettedAds,Artifact,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,targeted ads,
14,LackOfConsent,Perceived_Need,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,they did not consent to being targeted for online advertising,
15,FrustrationAtMisunderstanding,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,frustrated at being misunderstood,
16,FeelingOfAlgorithmicProfiling,Causal_Theory,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,felt alarmed that data brokers had algorithmically profiled their gender identity and sexual orientation.,
17,People,Agent,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,people,
18,Participants,Agent,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,participants,
19,DisrputionOfBrowsing,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,disrupted their normal browsing experience,
20,MisguidedGuesswork,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia.",
21,ContextCollapse,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"context collapse, or “how people, information, and norms from one context seep into the bounds of another”",
22,CompulsionToBuy,Perceived_Need,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,compelled to buy things they did not need ,
23,CompulsionToShopElsewhere,Perceived_Need,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. ",
24,FeelingOfDiscrimination,Causal_Theory,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,feeling discriminated against when they saw certain targeted ads.,
25,Triggering,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"painful triggers for participants,",
26,LGBTQParticipants,Agent,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,participants who were members of the LGBTQ community ,
27,LossOfTimeAndEffort,Perceived_Problem,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,a loss of time and effort in real life.,
28,BeliefInLimits,Causal_Theory,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,felt that certain information should simply be off-limits as a basis for targeting,
29, , , , , ,
30,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
31,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
32,HarmsFromOnlineBehavioralAdvertising,constrainsAgent,People,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,the different ways people report having been harmed by OBA
33,UnsettledByTargetedAds,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads.
34,DisrputionOfBrowsing,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,participants expressed that the targeted ads disrupted their normal browsing experience
35,LossOfTimeAndEffort,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,This inundation could also translate to a loss of time and effort in real life.
36,DesireForExplanationsForTargeting,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers.
37,BrowingMistakeRegret,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics
38,MisguidedGuesswork,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia."
39,LackOfConsent,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising
40,FrustrationAtMisunderstanding,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,They felt frustrated at being misunderstood
41,TargettedAds,influencesPrecept,ContextCollapse,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another”"
42,TargettedAds,influencesPrecept,CompulsionToBuy,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,A few participants felt compelled to buy things they did not need because they kept seeing ads for them.
43,TargettedAds,influencesPrecept,CompulsionToShopElsewhere,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"On the other hand, for some participants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. "
44,BeliefInLimits,constrainsAgent,Participants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,Some participants felt that certain information should simply be off-limits as a basis for targeting
45,TargettedAds,influencesPrecept,FeelingOfDiscrimination,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,Multiple participants reported feeling discriminated against when they saw certain targeted ads.
46,TargettedAds,influencesPrecept,Triggering,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"Ads related to eating disorders and body image can serve as constant painful triggers for participants,"
47,FeelingOfAlgorithmicProfiling,constrainsAgent,LGBTQParticipants,"People’s negative reactions to online behavioral advertising (OBA) are well-documented. However, past work has primarily focused on cataloging these reactions and exploring how to change them,rather than understanding the ways these negative reactions affect people's lived experiences. Drawing upon scholarship on socio-technical harms in human-computer interaction and computer-supported cooperative work, we investigate and categorize the dif-ferent ways people report having been harmed by OBA. Through an online survey with 420 participants, we identified four key harm arising from OBA: psychological distress, loss of autonomy, con-striction of user behavior, and algorithmic marginalization and traumatization. We next discuss the “slow violence” inflicted by OBA and the normalization of people’s affective discomfort withOBA, and how the two can present an opportunity for researchers tore-conceptualize OBA—and the invasive data practices it entails—not just abstractly concerning to people, but as actively harmful. [...] While the literature is clear that people find OBA creepy, unsettling,and threatening, how OBA materially and negatively impacts lived experience remains unclear. Building on prior work systematiz-ing the harms of socio-technical systems, we aimed to systematize the many concrete ways OBA can harm. We conducted an online survey on Prolific, a crowd-work platform, with 420 participants who had indicated in a screener questionnaire that they had previ-ously experienced a privacy violation related to online targeted or behavioral advertising. We first screened 1275 potential participants by asking them if they had recently experienced feeling violated by OBA. These potential participants were adults located in the United States, fluent in English, and active users of Internet-based services like social media, smartphone, or a smart home device. This screener took on average less than a minute to complete; participants were compensated 0.25USD on the Prolific platform. Those who answered “yes” to thescreener (n=420) were recruited to participate in the main study, a short survey hosted on Qualtrics. The main survey took on average 5 minutes, for which participants were compensated 1.50 USD. Ourstudy was approved by the Georgia Tech IRB. There were three main components to the survey. First, after reminding participants that they had previously told us that they had a recent privacy-violating experience involving OBA, we asked if they wanted to tell us about the experience in more detail. Be-ause such experiences can be sensitive in nature and difficult to talk about, we gave participants the option not to tell us about the experience at all. Second, if a participant agreed to share their expe-rience, to encourage richer qualitative contributions beyond simply describing it as “creepy”, we suggested details to include in their account of the experience: the parties and information involved,any actions they took in response to the incident, emotional reac-tions, changes in how they used the Internet, or why the incident was personally impactful. If a participant chose not to share an account, to ensure participants were being equally compensated for the same amount of work, we asked them if there were other privacy harms or violations unrelated to OBA they would be willing to share instead. Finally, we asked the participants why they did or didn't, respectively, choose to contribute to our study.To understand the many ways OBA can harm or burden people,we applied an inductive approach to qualitative data analysis. Onemember of the research team read through each of the accounts provided by participants and performed open coding, iteratively updating the codebook as necessary. The researcher then performed an initial round of axial coding to consolidate codes into different types of reactions to online targeted advertising, as well as any descriptions of the content of the ads or where the experience took place. A second researcher independently coded the data accord-ing to the codebook. Through multiple discussions, all members of the research team consolidated and synthesized the concepts into broader categories. The qualitative accounts, by their privacy-violating nature, described how online targeted ads negatively affected participants. Wethus grouped codes and concepts based on the nature of the nega-tive effect the experience had on the participants; more specifically,we examined them through a lens of harm. As aforementioned,through our coding process and multiple iterative discussions, and taking inspiration from prior work [15, 20, 48], we developed four broad categories of harms that we summarize in Table 2 and discuss in detail in Section 4. We first provide a demographic breakdown of participants based on whether they chose to contribute an account of their experiences.We then report on a broad overview of the online platforms where these accounts took place. Finally, in the bulk of the section, we discuss four broad categories of harms that can arise from online behavioral advertising: psychological distress, loss of autonomy,behavior constriction, and algorithmic marginalization and trauma-tization. We note that these harms are not mutually exclusive, but have distinguishing characteristics as described in Table 2.4.1 Quantitative breakdown 4.1.1 Participant demographics. In total, 315 participants chose to share an account; 105 chose not to. A summary of the demographics of our participants can be found in Table 1. They are grouped by whether or not they chose to contribute an account of their experiences.4.1.2 Where accounts took place. Over half of participants men-tioned specific companies or websites as the source of their expe-riences with OBA. Meta products were the most-mentioned site of violating experiences, with 84 participants mentioning an experience involving Facebook, and 55 mentioning Instagram. 49participants mentioned Google, and 18 mentioned YouTube specifi-cally. 20 participants mentioned Amazon or Alexa devices. Only 5 participants mentioned TikTok. 140 participants did not name a specific company or site; however, 34 of these participants men-tioned seeing ads on “social media”generally, and 10 participants said the advertising was “everywhere”.4.2 Psychological distress Psychological harms involve a wide range of negative mental responses, but typically fall into two primary buckets: emotional distress, i.e., painful or unpleasant feelings; and disturbance, i.e.,disruption to peace of mind. In the following subsections, we discuss different examples of both types of psychological harms.4.2.1 General emotional distress. As Citron and Solove argue [15],one of the most common types of harm caused by privacy violations is emotional distress. Our participants’ experiences provide empir-ical support for this claim: a fifth of accounts mentioned feeling unsettled by or uncomfortable with the specificity of targeted ads. For example, P326 expressed discomfort with the uncertainty and lack of transparency on what data is collected and the inferences that could be made thereof: “[Google] knew I was interested [in anew phone] because I had said so, out loud, to my girlfriend on a private call. If they hear that, who knows what else they hear? And What could be done with that information?”4.2.2 Disruption of browsing experience. Other participants expressed that the targeted ads disrupted their normal browsing experience. For example, P284 was angry and frustrated with seeing ads after they finished comparing an item’s price at Walmart: “I Was done needing to see Walmart, and now it’s all over the searches and websites afterward.” Similarly, other participants felt that they wanted to search for things independently, rather than have thatsearch be re-incorporated into an ad targeting experience: “Youcan’t just search anything anymore without being bombarded by ads”(P171). Some participants saw so many targeted ads that they had trouble distinguishing what was an ad: “I lose track of the number of real posts I see [on Facebook] vs. ads these days” (P160).4.2.3 Information redundancy. Sometimes, the sheer amount of targeted advertising from specific advertisers resulted in partici-pants being oversaturated with redundant information. For example,P188 was frustrated with repeatedly seeing the exact same ad from Halara, a clothing retailer: “After the third time I felt very frustrated and bored. This ad was haunting me and honestly I don’t think Iwould buy from this company now. It annoyed me so much. I wouldmute my computer while it played and try to skip it as soon as possi-ble.” Another participant who was targeted with ads from a guitar retailer said they were “inundated with advertising...for other guitars on unrelated sites repeatedly. This presumes upon my attention and cognitive/emotional space and angers me” (P243). This inundation could also translate to a loss of time and effort in real life. P154 Noted that even if they had blocked ads online, they still received corresponding physical marketing in the mail: “I’ve cleared my cache and cookies since but I’ll be receiving snail mail for generations. I get angry about this marketing because it consumes my time to throw everything away...I have to shred every offer that comes in the mail.Waste of paper, waste of resources, waste of time and energy.”4.2.4 Questioning own browsing behavior. Beyond feeling annoyed or overwhelmed by targeted ads, however, we also found that par-ticipants frequently tried to guess at where the ads came from. Thisechos prior work [27] that found that users wanted explanations for ad targeting explanations to confirm their own preconceptions of how their data was collected or the motives of advertisers. For example, multiple participants mentioned that ads “must have” come from their browsing and search history or their online chats with friends and family. P358 surmised that ads related to their personal shopping showed up on their work computer due to sometimes logging into their personal accounts at work: “We are a Microsoft-based system [at work] but at times I have clients send me GoogleDrives, etc. which requires me to log into my Gmail. I suspect that show these ads came to be on my work computer.” Some participants approached ads like a mystery to be solved with breadcrumbs of all the places where they had encountered certain ads:When I turned on another computer that I watch stream-ing television on, the same topic ads were on there, as well. I concluded that Google targets ads by your router’sIP...and then dispenses ads to all machines connected that IP, through your router. If you look up porn, beware that porn ads could show up on their computer, because of the general use of ads pointed at your domain.(P378)Others expressed disgust at the tracking after after detailing their browsing behavior step by step. P248, for example, shared how they looked up a clothing brand in Chrome on a work device, and thensaw related ads on their personal device while using Firefox: “I Clicked on those items in a different browser in a different physical location. I felt absolutely stalked by this ad.” Similarly, after retracing their digital breadcrumbs, some participants then expressed regret about mistakes they had made along the way when researching and discussing the related ad topics. P154 shared that they forgot to block cookies on a credit card website one time, and have regretted it ever since: “I forgot to deselect the marketing cookies once on a credit card website...but now every single website has credit card offers.”4.2.5 Paranoia from suspicion of eavesdropping. When their in-vestigations into the origins of targeted ads reached dead ends,participants often felt that the only possible explanation was that their devices were eavesdropping on them. Several participants felt that merely mentioning a product in a real life conversation with a friend or family member would result in seeing ads for that product, whether it be spices (P42), cat food (P49), electric tooth-brushes (P56), hula hoops (P90), or press-on nails (P131). While the concept of smart and mobile devices—in particular, Facebook and Meta—eavesdropping on users via microphones has been frequently debunked in popular news media and prior work [34], the myth persists. The lack of transparency and trustworthiness surrounding these ad targeting practices[6] necessitates misguided guesswork on the part of the users, which results in concrete harms: constant suspicion, fear, and paranoia. The immediacy and consistency with which targeted ads appear made participants suspicious of their microphone-enabled devices:“An Alexa device was in the same room, but was off, or so we thought. On more than one occasion the items we discussed showed up almost immediately on our devices (email, internet ads, social media, etc.)”(P20). Similarly, P60 shares:I don’t have an Alexa or anything like that, but somehow my phone is apparently listening any-way? I don’t know what to think. These are pri-vate conversations! And I know that I haven't just entered any of that into the search window on my phone or computer. It has happened far too many times for it to be coincidence and allI can assume is nothing is private anymore. It’s sickening. Some more tech-savvy participants admitted that even though they were educated otherwise about microphone eavesdropping,they still felt concerned. For example, as P1 described, “While I know rationally that these programs aren’t listening, it is very unsettling that they are reading my data to target ads to me.” Similarly, P36said they closed the Instagram app on their phone as soon as they were done using it, even though “I know it supposedly doesn’t listening but rather tracks you in other ways...but sometimes the ads are a little too targeted for comfort”. P55 adds that the targeting is simply too accurate and immediate to ignore: “While it is possible that it’s a coincidence and social media shouldn’t have access to my microphone to capture data and tailor advertisements to me, I can’t help but feel creeped out and paranoid that I’m being recorded at all times.” Thesepersistent fears are direct vectors to psychological harm.Autonomy harms involve accounts where participants were prevented from making their own choices, either via being directly denied these choices, being tricked into thinking their choices were freely made when they were not, or being limited in the choices they could make. These harms recall Zuboff [50], who wrote that in surveillance capitalism, “the surest way [for advertisers] to predict behavior is to intervene at its source and shape it”. In the following subsections, we discuss different types of autonomy harms.4.3.1 Lack of consent or control over targeting. One of the most common concerns that participants voiced was that they did not consent to being targeted for online advertising. Some participants,for example, felt violated when they saw online advertisements based on purchases they’d made in a physical store. P77 shared how they had seen ads related to groceries they bought in a physical store, but had never expressly consented to connecting these pur-chases with any shopping website or app: “I feel it should be against the law to...invade my privacy without express permission each time they want to do something like this.”Others felt like they had no control over the nature of the tar-geting, even when the targeting was incorrect. For example, one participant was researching flooring materials on behalf of their mother, but still received endless ads related to it. They felt frus-trated at being misunderstood: The flooring isn’t really for me, but just in my searching,I’ve had countless ads and emails sent to me about all kinds of flooring. I’ve even had other companies sending me info about flooring. I feel like I’m being attacked by salesman at a used car dealership and I really have no control over it. (P351)Other participants noted that even though they understood their data was being collected online, it still felt like a breach of consent.Participants found the pervasiveness and specificity of the ads overwhelming, describing a mission or scope creep of sorts: “It's Not even what I’m doing anymore, it’s everything I am thinking”(P49).4.3.2 Lack of control over self-presentation. Several participants mentioned seeing ads on devices they used at work that were related to interests in their personal life, or vice versa. This exemplifies context collapse, or “how people, information, and norms from one context seep into the bounds of another” [17]. Participants who experienced context collapse felt they had little control over the consequences, usually in the form of the targeted ads unwittingly revealing private information about themselves. One immediate harm of this phenomenon was social embarrass-ment, as P358 writes:About a year ago, I had been shopping for lingerie for honeymoon. This was only on my personal laptop. I Had a coworker in my office looking up some informa-tion with me. I believe it was thesaurus.com or some-thing like that, but I can’t fully remember because what was ON the page was so mortifying. There, in front of my coworker, on my WORK computer, were specialized ads for lingerie. I was so embarrassed. I tried to ignore the ads that seemed to be disproportionately large on the screen. My coworker thankfully did not mention them, but now probably thinks I shop for lingerie while at work.Other participants noted that even friends who talk to them about sensitive problems could influence the ads they saw and result in negative outcomes. For example, P124 mentioned speaking to a friend about the friend’s pending divorce, and subsequently got ads related to divorce lawyers. This made the participant concerned that their own spouse would accidentally see these ads and misinterpret them: “This could potentially lead to misunderstandings with my spouse. What if I was showing them something on my phone and divorce attorney ad came up?”Relatedly, participants also experienced context collapse with family members directly. P363, who had shared their Facebook cre-dentials with their mother, described how their mother saw ads from their feed for explicit content and surmised that those ads were based on P363’s own browsing behavior. The ads thus revealed pri-vate information about P363 to their mother without their consent,making P363’s relationship with their mother “uncomfortable for along time”. Another participant shared that a surprise birthday gift for their husband was ruined when the husband was targeted with ads related to the participant’s search history. As a result of this ruined surprise (a harm in itself), they began altering the way they used the Internet out of persistent concern that future surprises could be ruined too:I have started only using my desktop at work to search for presents for people in my family. I’m paranoid even to buy gifts for my parents and in-laws on our familycomputer, though they don’t live with us and the chances they will use our family desktop to search the web is very small. But just in case one day they need to use the computer, I don’t want them to see the gift I am searching for them! (P192)Similarly, P265, who researched medical treatments on behalf of a friend, felt constantly reminded of their friend’s heart prob-lems. They also now felt burdened with protecting not only their own privacy, but that of their friend, too: “I was not looking up the information for myself, but for a friend. I cannot go to most sites without seeing ads for TAVR (transcatheter aortic valve replacement)and now other heart problems. I will be careful about searching for sensitive information for both myself and my friends”. P239 offered a similarly sensitive account of searching for resources for theirsister-in-law who was dealing with marital rape: “I started seeingads related to mental health to help rape victims. I do not know who actually made the ads. It was a constant reminder of the abuse thatshe went through.”4.3.3 Encouraging negative purchasing habits. A few participants felt compelled to buy things they did not need because they kept seeing ads for them. For example, P35 described themselves as“impulsive with my money”, and said that a stream of targeted ads“makes it hard to use social media when I see ads for clothing that Iwant but cannot afford.”4.3.4 Limiting consumer choice. On the other hand, for some par-ticipants, companies that used OBA were so off-putting that it compelled them to limit their choice set of things to buy and shop elsewhere, so as not to reward bad behavior. Several participants stated that the fact the advertiser was directly pandering to them made them not want to purchase anything from that advertiser. For Example, a few participants felt that if an advertiser was spending so many resources on marketing targeted toward them, it must be a signal of a deficiency in the products being advertised. P18 Wondered, “If they [an e-bike company] have the budget to spend so much on targeted advertising, what is wrong with their e-bikes? Iwonder if they are charging too much or that the product is of much lower quality than their competitors.” More bluntly, P408 said, “I Become so disinterested and put off by these practices I look at other brands, and I would NEVER click on such an ad regardless of my level of seriousness to purchase such a product.” As we argued previously, users can face usability burdens when dealing with online targeted ads. Multiple participants mentioned taking privacy-protecting measures, such as disabling advertising-related tracking, deleting accounts on retail websites, and erasing browsing history. But even though they went through so much effort, participants felt they could not escape the ads. Despite having all “privacy flags available set to the maximum”, P167 said, “the tracking persists. I feel powerless to prevent this from occurring.” Not only are the effort and time taken to implement these seemingly futile measures an unwelcome burden for the average user to bear,but users are also penalized with a loss in usability and utility when they are forced to use services or devices in less-than-optimal ways.Perceptions of microphone eavesdropping elicited specific ac-tions from participants. One participant mentioned disabling Sirion their iPhone “so that it was not able to listen at all hours” (P19),limiting themselves from accessing the full functionality or conve-nience of their personal phone. We acknowledge that disabling Siri was an active choice on the part of the participant, and the immedi-ate inconvenience of not being able to use Siri might seem like an innocuous harm. However, it’s easy to imagine a scenario where opting out of one tool can lead to more extreme consequences, or the cost of opting out is greater than simply switching off a button.As one example of the former, P119 shared that after making therapy appointments online, they saw ads related to depression and PTSD. As a result, they stopped booking their appointments online and instead could only do so over the phone. While this might only appear to be a minor inconvenience on the surface, people with social anxiety or social phobia could find the idea of making a phonecall paralyzing, and may rely on online booking services. (In Section 4.5, we discuss in detail harms that specifically come from ads with sensitive content or offensive profiling). And, as an example of the latter, P340 said that they had “removed all [Amazon] Alexa devices from their home and shut down all web camera (sic)”, entailing a not-insignificant amount of time unplugging and covering up all their devices, and not to mention the money lost on purchasing the devices in the first place.Several other participants mentioned avoiding having conversa-tions about potential purchases or changing the way they talk to their friends to steer clear of getting related ads. For example, asP259 put it, “I take the approach ‘the walls have ears’ and typically act as if someone (like my boss, for example) were listening [in] on my conversation, because it’s clear that what I say in private might not actually be private anymore.” P55 said, out of fear of eavesdropping,they started physically separating themselves from their phone: “Idon’t carry my phone with me into other rooms if I am hanging outwith someone and if I need to search something up, I have to go and grab my phone from wherever I left it. I feel the need to keep distance in order to maintain some sort of privacy and to ease my paranoia.” OBA based on user interests can over-simplify those interests and hone in on user vulnerabilities. Echoing prior work [20], we found that when users identified as part of a sensitive “interest” group,they were particularly vocal about being violated. We distinguish these harms from general psychological distress (Section 4.2) due to how these ads diminish people by highlighting their specific personal characteristics or vulnerabilities.4.5.1 Violation of boundaries. Some participants felt that certain information should simply be off-limits as a basis for targeting. For Example, one participant dealing with the death of a loved one felt that targeted ads related to funeral services tried to exploit their private grief: “It was inappropriate to intrude on our grieving with an attempt to get us to spend money on elaborate funeral services or gouging us for insurance” (P130).These limits also applied to medical histories. For one, even if participants felt that the medical treatments promoted in certain targeted ads were valid, they were still disturbed that data brokers knew about their medical history and targeted them for it. For Example, P244 felt that they were shown ads related to substance abuse treatment programs because of their history of opiate abuse,and were upset with how Facebook concluded this about them: “It Reminded me of a very dark time that I would like to forget. I am not against the company or the treatment program, just how Facebookselected me for targeted advertising.” P273 felt that seeing ads related to a medical condition on Twitter, Instagram, and Facebook, “wasakin to a HIPAA violation.”4.5.2 Amplification of self-consciousness. Multiple participants reported feeling discriminated against when they saw certain targeted ads. Some older female participants reported seeing ads related to menopause, and said they felt uncomfortable that so much attention was being drawn to their age. As P249 writes, “Few women like to have this stage of life rubbed in their faces by a social network, for goodness' sake...I didn’t feel ashamed; I felt really depressed. I don't like to dwell on things that basically say to me, ‘Say, I hear you're growing OLD, girl!”’ P366, who self-identified as a woman, said they started seeing ads for Botox and plastic surgeons “EVERYWHERE”when they entered their age into Instagram; they felt this promotes ageism. To avoid these ads, P366 created a new account with a fakeage (evoking Section 4.4).Participants also felt misrepresented and hurt by ads referencing neurodiversity. P2 shared an experience with ads related to autism,which unsettled them not only due to the sensitive topic, but also misleading portrayals of autism:I was recently diagnosed with autism. In the follow-ing week, I was getting tons of ads on Facebook about“holistic medications” and “lifestyle changes” that help people to be “less autistic.” Additionally, I was getting sponsored content from Autism Speaks and moms in the community. The ads were hurtful. Autism is a neu-rotype, not something that can be “cured”, especially by unregulated supplements or diets. I think targeted misinformation like this is extremely sinister.Similarly, specific representations of neurodiversity in targeted ads made participants self-conscious about how they were per-ceived by others in real life, and caused them to alter their browsing behavior. One participant felt hurt due to an ad that portrayed peo-ple with ADHD as “closed off and goofy”, and said that it “showed[ADHD] to be more lighthearted than it actually was. Now I’m a bitmore self-conscious thinking others have seen the advertisement and are judging me. Now I know to be more careful with what I search”(P126).4.5.3 Traumatic triggers. Ads related to eating disorders and body image can serve as constant painful triggers for participants, echo-ing prior work [20]. For example, P78, who actively participates in an anonymous eating disorder forum, started getting ads for both erectile dysfunction and weight loss programs. They felt that seeing these ads outside of the forum was “damaging to my mental and ultimately physical health, as they are constant reminders of my restrictive eating problem.” Similarly, P206, who discussed body image and weight issues with friends and family members, noticed“an increase in various weight loss ads across my social media plat-forms. Instagram has given me ad after ad for diet plans and paid exercise programs. I felt like every ad I saw was pointing out my insecurities and confirming my embarrassment in my appearance.Since this started, I have felt very unsafe on the internet.”In a similar vein, participants dealing with bereavement also felt that seeing ads related to funeral services prevented them from moving on with their grief. P341, completely exasperated, expressed regret at looking up headstones for their grandmother on Google:“Well that was a mistake, because to this day I get reminded multiple times a day that I had to lay my grandmother to rest. I see multiple ads a day on Google, Facebook. I’m over it. I just want to be able to mourn and let it go. At this point I don’t want to ever Google anything again.”4.5.4 Fear of social exposure. Beyond the immediately obvious harms of reductive ads based on demographics, participants also worried about secondary social ramifications of such ads. For exam-ple, participants who were members of the LGBTQ community feltalarmed that data brokers had algorithmically profiled their gender identity and sexual orientation. For one, they expressed anxiety about how these characteristics were inferred in the first place,especially if they themselves had not yet come out. For example,P173 wrote:I am closeted on Facebook (not out as trans, neutral name, lots of family members added, had not yet changed my pronouns on the site) and it started advertising products aimed specifically at trans men to me—[chest]binders, online medical services for HRT [hormone replacement therapy], etc. I had not shopped for any rel-evant products. I do not know why Facebook decided I Was/am a trans man. I am anonymous on other Face-book products like Instagram, no mention of gender pronouns there at all, let alone my correct pronouns.As another, more immediate danger, P164 shared how they were afraid of exposure of their gender identity at work. This fear also constricted how they used their phone at work:My coworkers do not know that I am transgender. Before meeting we were all...scrolling through our phones. I Got a targeted ad for a trans pride flag that was large and very visible. I immediately got scared that people behind or beside me would see so I quickly closed my phone and put it away. Now I don’t open my phone when I’m in the same room with coworkers. I’m not trying to get outed in an unsafe way.Participants who were already out were still concerned. P214,for example, described a conversation with their boyfriend about underwear unrelated to their sexual orientation, but seemingly led to targeted ads about underwear for gay men: “It felt wrong,especially when being gay is criminalized in some countries and evendemonized among communities in the U.S. It’s potentially dangerous if someone else sees an ad that’s targeted towards something private about you.",1828-33,"For example, participants who were members of the LGBTQ community felt alarmed that data brokers had algorithmically profiled their gender identity and sexual orientation."
