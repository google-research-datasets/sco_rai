,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{kwegyireaggrey2023, author = {Kwegyir-Aggrey, Kweku and Gerchick, Marissa and Mohan, Malika and Horowitz, Aaron and Venkatasubramanian, Suresh},
title = {The Misuse of AUC: What High Impact Risk Assessment Gets Wrong},
year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,USStates,Agent,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,many states throughout the U.S. ,
10,RiskAssessmentInstrumentDeployments,Artifact,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,Risk assessment instruments are currently used,
11,USDepartmentOfJustice,Agent,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,the U.S. Department of Justice,
12,PATTERN,Artifact,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,PATTERN is a risk assessment tool ,
13,PATTERN,Agent,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,PATTERN is a risk assessment tool ,
14,Stakeholders,Agent,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"Civil Rights organizations, researchers, impacted community members and other stakeholders ",
15,RacialDisrimination,Perceived_Problem,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,the racial discrimination of the criminal legal system,
16,AreaUnderCurve,Strategy,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,AUC,
17,ClassImbalance,Causal_Theory,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,the class imbalance in the violent recidivism sample,
18,LimitationsOfAUC,Perceived_Need,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation”",
19,Thresholds,Other_Precept,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,thresholds,
20,CriminalJusticeDecisions,Strategy,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more ",
21,RecidivismPredictions,Artifact,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison.,
22,CriticismOfPATTERN,Artifact,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use",
23, , , , , ,
24,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
25,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
26,USStates,hasProducedArtifact,RiskAssessmentInstrumentDeployments,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system.
27,RiskAssessmentInstrumentDeployments,influencesPrecept,CriminalJusticeDecisions,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more "
28,USDepartmentOfJustice,hasProducedArtifact,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,PATTERN is a risk assessment tool currently used by the U.S. Department of Justice to evaluate people incarcerated in federal prisons.
29,PATTERN,hasProducedArtifact,RecidivismPredictions,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison."
30,Stakeholders,hasProducedArtifact,CriticismOfPATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use"
31,RacialDisrimination,constrainsAgent,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system
32,AreaUnderCurve,constrainsAgent,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,AUC has been a key metric underpinning PATTERN since the tool was developed in 2019.
33,ClassImbalance,constrainsAgent,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment
34,LimitationsOfAUC,constrainsAgent,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,"the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation”"
35,Thresholds,constrainsAgent,PATTERN,"Risk assessment instruments are currently used in many states throughout the U.S. at various stages of the criminal legal system. These assessments are used to inform pretrial release decisions,sentencing decisions, decisions about the services that will be made available to people who are incarcerated, and more [49, 72, 94]. Researchers, civil rights organizations, community members, policymakers and others have extensively criticized and debated these tools and the manner in which they contribute to racial bias in the criminal legal system [5, 23, 24, 33]. For many of these risk assess-ments, AUC plays an important role in the tool’s creation and use. In This section, we’ll primarily discuss a criminal risk assessment tool called the “Prisoner Assessment Tool Targeting Estimated Risk andNeeds” or PATTERN. We claim that PATTERN’s use is predicated on many of the problems summarized in Section 4.4 and contextualize these issues through an analysis of PATTERN’s threshold cutoffs,noting the clear policy implications of the threshold setting. PATTERN is a risk assessment tool currently used by the U.S.Department of Justice to evaluate people incarcerated in federal prisons. The tool, which was developed in connection with the FirstStep Act of 2018 [72], attempts to estimate the likelihood that a person will be rearrested or returned to federal custody following release from federal prison. Since the first version of PATTERN was developed in 2019, the tool has been substantively altered several times (as of writing, PATTERN 1.3, the third version of the tool,is currently in use). PATTERN 1.3 has separate male and female assessments and also produces two separate risk scores, one for“general recidivism” and one for “violent recidivism.” Thresholdsare applied to each score to group incarcerated people into “risk level categories,” and for each person, these “risk level categories”based on the two different risk scores are aggregated. PATTERNs outputs directly determine some of the resources individuals are able to access while incarcerated and their ability to earn credits for programming that can be applied towards earlier release [68]. Civil Rights organizations, researchers, impacted community members and other stakeholders have repeatedly criticized PATTERN since it was developed, highlighting numerous serious issues with the tools design, development, and use. These issues include PATTERNs reliance on data that reflects the racial discrimination of the criminal legal system, problematic use of the tool at the onset of the COVID-19 pandemic, and serious errors with both the technical systems and human processes used to calculate PATTERN scores – errors that have led to miscalculated risk scores for tens of thousands of people [4, 18, 41, 73]. AUC has been a key metric underpinning PATTERN since the tool was developed in 2019. While not the only metric used to eval-uate PATTERN, AUC has been used to justify the tool’s creation,to inform model development, and to make arguments about PAT-TERN’s “racial neutrality.” While the use of AUC as a validation metric is not inherently bad, in the context of PATTERN, AUChas been used to make conclusions about the tool in ways that suffer from the issues discussed in Section 4. For example, a 2019 development report describing the first version of the tool statesthat the research team “rel[ied] on the AUC as the primary metric for evaluating predictive validity” [72, p. 50]. The report comparesAUC values for PATTERN to reported AUC for other criminal risk assessment instruments, concluding that “PATTERN achieves higher level of predictability and surpasses common risk assess-ment tools for correctional population in the U.S.” [72, p. 56]. Inone telling visualization, the tool’s creators declare that PATTERN is “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.As we discuss in Section 4.1, it is important to note the level of class imbalance associated with these results. For the PATTERN general recidivism tool, the sample was roughly balanced – 45.4%of individuals in the sample experienced a return to custody or a re-arrest within three years of release from incarceration. Conversely, for the violent recidivism tool, the sample was highly imbalanced (15% of individuals were rearrested for a suspected act of violence within three years of release from incarceration) [68, p. 15]. Importantly, under current DOJ practice, an individual’s score on the violent recidivism tool overrides their score on the general recidi-vism tool [67, p. 13], so the class imbalance in the violent recidivism sample (and the resulting effects on interpreting the AUC) has the potential to affect PATTERN as a whole upon deployment. For the violent recidivism tool, with a reported AUC of .77 - .78 on this sample [72, p. 57], the underlying classifier, in the average case, haserror around 7.5% (see Table 3). Note that while this error rate may seem benign, it does not tell the full story: this error rate could be achieved by misclassifying up to 50% of the people rearrested for suspected act of violence.8In its most recent validation reports, the Department does acknowledge some of the limitations of AUC, stating that AUC is “less useful for gauging the accuracy of a risk tool as used in practice. For instance, the AUC does not provide information about the accu-racy of the high-risk [risk-level category] designation” [68, p. 22].Though the Department makes this acknowledgement and includes some threshold-specific evaluation metrics in recent reports about PATTERN, it still relies on AUC to justify the tool’s continued use and to examine PATTERNs “racial and ethnic neutrality,” grouping by race and comparing AUC values in recent validation reports[68, 71], a practice also employed in prior validations of PATTERN [69, 70]. For example, a 2020 report stated that, with regard to racial bias, “PATTERN is a neutral assessment tool, as evidenced by the nearly equal scores [for different racial groups] on the AreaUnder the Curve (AUC) analysis” [69, p. 9] – a statement that, as highlighted in Section 4.3, reflects an inaccurate interpretation ofAUC. As highlighted in Section 4.2, AUC does not evaluate the per-formance of a model at specific thresholds – but thresholds are crucial to PATTERN’s deployment, and setting thresholds for a toollike PATTERN is arguably an important question of policy. TheFirst Step Act of 2018 requires that PATTERN classify each incar-cerated person as either minimum, low, medium, or high risk for recidivism [72]. The Department of Justice has repeatedly altered the thresholds that define these risk categories. The thresholds for the earliest version of PATTERN were developed by relying on the base rate of recidivism (re-arrest or return to custody), using different thresholds for the male and female scales and the “general recidivism” and “violent recidivism” scales [72, p. 50]. In subse-quent validation reports, the Department describes procedures for repeatedly changing these cut points for various reasons [68–70] “15% more predictive” than other criminal risk assessment tools because its AUCs are roughly 15% higher than the average of the reported AUCs of several other criminal risk assessment tools [72,p. 57] – a conclusion that is unsupported on the basis of a mereAUC comparison alone, as discussed in Section 4.",1576-77,but thresholds are crucial to PATTERN’s deployment
