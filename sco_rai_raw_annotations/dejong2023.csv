,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{dejong2023, author = {De Jonge, Tim and Hiemstra, Djoerd}, title = {UNFair: Search Engine Manipulation, Undetectable by Amortized Inequity}, year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-12, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,InteractionsWithMockSearchEngine,Other_Precept,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"the results of a mock search engine, ",
10,MockSearchEngine,Artifact,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"the results of a mock search engine, ",
11,InfluenceInTheDirectionOfTheManipulation,Perceived_Problem,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,The net probability of influencing a vote in the direction of the manipulation could be as high as 25% ,
12,SlightNegativeResponse,Other_Precept,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results",
13,InabilityToDetectSearchEngineManipulation,Perceived_Problem,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,The manipulation of search results can be difficult to detect,
14,DifficultyFindingSearchEnginePatterns,Perceived_Problem,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,it can be hard to find patterns in the results provided by a search engine.,
15,Participants,Agent,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,participants,
16,HeavyPoliticalSkew,Causal_Theory,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,heavily politically skewed,
17,LowInformationModerates,Agent,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"the most susceptible sub-group of the population: poorly informed, moderate voters",
18,LessSusceptiblevoters,Agent,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,the least susceptible subgroup,
19,EndUsers,Agent,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,end-users,
20, , , , , ,
21, , , , , ,
22, , , , , ,
23,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
24,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
25,InteractionsWithMockSearchEngine,constrainsAgent,Participants,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"they showed participants the results of a mock search engine, manipulated to be heavily politically skewed"
26,MockSearchEngine,reflectsPrecept,HeavyPoliticalSkew,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"they showed participants the results of a mock search engine, manipulated to be heavily politically skewed"
27,InfluenceInTheDirectionOfTheManipulation,constrainsAgent,LowInformationModerates,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters"
28,SlightNegativeResponse,constrainsAgent,LessSusceptiblevoters,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results"
29,InabilityToDetectSearchEngineManipulation,constrainsAgent,EndUsers,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,The manipulation of search results can be difficult to detect for end-users
30,DifficultyFindingSearchEnginePatterns,constrainsAgent,EndUsers,"As illustration of the societal harms that can result from Information Retrieval systems, we use the Search Engine Manipulation Effect. Epstein and Robertson [13] held an experiment in which they showed participants the results of a mock search engine, manipulated to be heavily politically skewed; their experimental design can be found in Figure 1. First, they polled their participants on a prospective election. They then asked the participants to interact with the search engine results page that was biased towards one of the candidates. They then polled the participants again, to see whether a shift had taken place. The results varied strongly with participants' features, and their prior knowledge of the election.The net probability of influencing a vote in the direction of the manipulation could be as high as 25% to the most susceptible sub-group of the population: poorly informed, moderate voters [13]. By Contrast, the least susceptible subgroup showed a slight negative response, making it less likely for the participant to vote for the candidate favored by the search results. [...] The manipulation of search results can be difficult to detect for end-users. Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine. Additionally, we cannot expect users to have the expertise required to detect bias in search results if they use a search engine to acquire knowledge in the first place. The Powerful position in which large tech companies find themselves, combined with the inability for individuals to realize something is afoot, makes for a nasty problem if manipulation through searchengines does take place.",831,"Since each user only interacts with the search engine a limited amount of times, it can be hard to find patterns in the results provided by a search engine."
