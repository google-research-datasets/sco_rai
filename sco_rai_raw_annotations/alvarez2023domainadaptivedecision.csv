,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{alvarez2023domainadaptivedecision,
    author = {Jose M. Alvarez and Kristen M. Scott and Bettina Berendt and Salvatore Ruggieri},
    title = {Domain Adaptive Decision Trees: Implications for Accuracy and Fairness},
    year = 2023
}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-12, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,USCensusTakers,Agent,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",the2017 US Census data,
10,PredictionTask,Artifact,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432","the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage.",
11,IndentifyBenefitEligible,Perceived_Problem,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",wants to identify individuals who do not receive the public benefits they are entitled to,
12,DADT,Agent,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",domain-adaptive decision trees (DADT) ,
13,Improvements,Goal,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree,
14,ACSPublicCoverage,Artifact,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",ACSPublicCoverage dataset,
15,Researchers,Agent,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",We,
16,PublicAdmin,Agent,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",a public administrator,
17,BetterPerformance,Artifact,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree,
18,CovariateShift,Artifact,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",when the covariate shift assumption holds,
19,DomainKnowledge,Artifact,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432","when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it,",
20, , , , , ,
21, , , , , ,
22, , , , , ,
23,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
24,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
25,USCensusTakers,hasProducedArtifact,ACSPublicCoverage,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data
26,Researchers,hasProducedArtifact,PredictionTask,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432","We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage."
27,IndentifyBenefitEligible,constrainsAgent,PublicAdmin,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",a public administrator wants to identify individuals who do not receive the public benefits they are entitled to
28,DADT,hasProducedArtifact,BetterPerformance,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree
29,CovariateShift,influencesPrecept,Improvements,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432",improvements are best when the covariate shift assumption holds
30,DomainKnowledge,influencesPrecept,Improvements,"We consider the ACSPublicCoverage datasetâ€”an excerpt from the2017 US Census data [6]â€”that provides the same feature sets for different geographical regions based on the US states, which may have different distributions. This allows us to examine the impact of our method given a wide range of distribution shifts. We utilize the prediction task, constructed by the dataset creators, of whether or not a low-income individual is covered by public health coverage. Inspired by this experimental setting, we imagine a task where a public administrator wants to identify individuals who do not receive the public benefits they are entitled to. Information about who does and does not receive these benefits, however, is only available for a population different from the target population: for example, the population from another state. This administrator is likely to have some information about the target population distribution; information that they realistically may have on population breakdown by demographics such as age, race and gender. To address RQ1 we now test whether, with DADT, we can utilize that information to train an improved model in the new state, compared to blindly applying a model trained in the other state. Additionally,we address RQ2 by testing the impact of using DADT instead of standard decision trees on two fairness metrics: demographic parity and equal opportunity. The design of the ACSPublicCoverage dataset allows us to set up a scenario that mirrors our example of the retail store in Section 1:we have unlabeled data for the target domain, but some knowledge of the (unconditional) distribution of the target domain. Here, how-ever, we extend the scenario by having access to the labeled data for each state. We note that the implementation of the DADT does not require this information, but we utilize our access to the target do-main labeled data in Section 4.2 to test our assumption that DADTs are suitable for addressing covariate shift. Given the dataset design,we are able to utilize the distribution of the predictive attributes in the target domain as our source of outside knowledge, to adjust the information gain calculation. Unless otherwise stated, we consider the attributes: SCHL (educational attainment), MAR (marital status),AGEP (age), SEX (male or female), CIT (citizenship status), RAC1P(race), with AGEP being continuous and all others discrete. Datawas accessed through the Python package Folktales.6 We consider pairs of source and target datasets consisting of data from different US states, with a model trained in each of the fifty states being tested on every state, for a total of 2500 train / testpairs. The decision trees are all trained on 75% of source data ğ·ğ‘† ,and tested on 25% of the target data ğ·ğ‘‡ . Stopping criteria include the following: a node must have at least 5% of the training data,and not all instances have the same class value (purity level set to100%), the maximum tree depth is 8.7To address RQ2, in particular, we undertake a post-processing approach to fairness based on the known link between a model's performance and its fairness [7, 14, 30]. The public administrator wants to evaluate the performance of the trained classifier on6https://github.com/zyklus/folktales 7The code, data, and run are available at https://github.com/nobias-project/domain-adaptive-trees.certain demographic groups in the target population. The adminis-trator thus resorts to applying a post-processing method around the classifier that adjusts the predictions under the chosen fairness metric. In practice, this comes down to using a wrapper function based on [12].We focus on this model agnostic post-processing fairness intervention to measure the impact of DADT on a fairness intervention.Post-processing methods rely on the non-DA setting, meaning thatğ‘ƒğ‘† (X, ğ‘Œ ) = ğ‘ƒğ‘‡ (X, ğ‘Œ ). Classifiers are a statement on the joint proba-bility distribution of the training data. Under DA, post-processing methods are essentially only modifying ğ‘ƒğ‘† (X, ğ‘Œ ). Granted the usertrains an oracle-like standard decision tree, the issue remains that the post-processing fairness intervention would only be address-ing issues on the source and not the target population. Therefore,DADT is expected to positively affect the fairness measure. [...] we see that domain-adaptive decision trees (DADT) result in both increased accuracy and better performance on fairness metrics over our baseline standard decision tree trained in ğ·ğ‘† and tested in ğ·ğ‘‡ . Looking more closely at our experimental results, we see that improvements are best when the covariate shift assumption holds in at least a relaxed form (P2). We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. Interestingly, our post-processing fairness intervention does not have worse performance over a standard decision tree even when the covariate shift assumption does not hold. ","428, 432","We also see this increase when we only have partial domain knowledge (P1), though a greater amount of domain knowledge,as we define it, results in greater improvements in those metrics. "
