,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{ovalle2023, author = {Ovalle, Anaelia and Goyal, Palash and Dhamala, Jwala and Jaggers, Zachary and Chang, Kai-Wei and Galstyan, Aram and Zemel, Richard and Gupta, Rahul}, title = {“I’m Fully Who I Am”: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation}, year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,TransNonConformingCommunity,Agent,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,real-world data from the TGN community ,
10,Researchers,Agent,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,we,
11,MisgenderingBehavior,Perceived_Problem,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"misgendering behavior in OLG,",
12,CoreferenceTools,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,coreference tools ,
13,Annotators,Agent,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"3 annotators per task, with269 unique annotators in total.",
14,MisgenderingEvaluationTool,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,an automatic misgendering evaluation tool.,
15,PronounBias,Perceived_Problem,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3).",
16,LessPerplexityForBinaryPronouns,Perceived_Need,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,resulted in the least perplexity when prompted with binary pronouns.,
17,StruggleToMakeSenseOfPronouns,Perceived_Need,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,still struggle to make sense of TGNB pronouns. ,
18,LessMisgenderingForDistalAntecedent,Perceived_Need,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,misgendering was least observed for singular they pronouns in prompts containing distal antecedents,
19,MalePronounPreference,Perceived_Problem,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,generations from he pronoun templates were the most frequent across all templates aside from she [...] Our findings also corroborate lin-guistics literature on “generic masculine” defaults,
20,TANGODataSet,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data ",
21,TemplatesForMisgenderingEvaluation,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"2,880 templates for misgendering evaluation",
22,GenderIdentityPrompts,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki [...] We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English.",
23,LargeLanguageModels,Agent,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,LLMs,
24,Annotations,Artifact,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"3 annotators per task, with269 unique annotators in total.",
25,CorrelationWithHumanJudgment,Causal_Theory,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,a moderately strong correlation between our automatic metric and AMT,
26, , , , , ,
27,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
28,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
29,TransNonConformingCommunity,hasProducedArtifact,TANGODataSet,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively"
30,Researchers,hasProducedArtifact,TemplatesForMisgenderingEvaluation,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"We created 2,880 templates for misgendering evaluation"
31,Researchers,hasProducedArtifact,GenderIdentityPrompts,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki [...] We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English."
32,MisgenderingBehavior,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"To assess LLMs for misgendering behavior in OLG,"
33,Researchers,hasProducedArtifact,MisgenderingEvaluationTool,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,we create an automatic misgendering evaluation tool.
34,CoreferenceTools,reflectsPrecept,PronounBias,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns)"
35,Annotators,hasProducedArtifact,Annotations,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"There were 3 annotators per task, with269 unique annotators in total."
36,MisgenderingEvaluationTool,reflectsPrecept,CorrelationWithHumanJudgment,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respectively)."
37,PronounBias,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3)."
38,LessPerplexityForBinaryPronouns,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,we observed that models resulted in the least perplexity when prompted with binary pronouns.
39,StruggleToMakeSenseOfPronouns,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns."
40,LessMisgenderingForDistalAntecedent,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents"
41,MalePronounPreference,constrainsAgent,LargeLanguageModels,"we propose a framework for assessing gender non-affirmation of TGNB identities. We focus on examining the Extent to which the undesired behavior of (1) misgendering and (2) negative responses to gender identity disclosure are present in open language generation. To this end, we propose TANGO, a dataset consisting of 2 sets of prompts grounded in real-world data from the TGN community to conduct such evaluations respectively.3.1 MisgenderingMotivation Misgendering10 is a form of gender non-affirmation experienced by the TGNB population that results in stigmatization and psychological distress [41]. To determine if this behavior per-sists in LLMs, we create a dataset to evaluate misgendering in OLG.In English grammar, pronouns should agree in number, person,and gender with their antecedents (i.e., a person, place, thing, or clause which a pronoun can represent), called pronoun-antecedent agreement [17]. Therefore, we create a set of prompts consisting of various antecedents and pronouns to measure this expected agreement – which we call pronoun consistency – in the models generated text. Pronouns measured included she, he, they, xe, ey,and fae (Table A1). An example prompt is the following:[Casey] is an author of children’s fantasy, best known for [their]book that won several awards.The antecedent is the name [Casey], who uses the pronoun[their]. If this prompt were followed by text referring to Caseyas he, this would be a case of misgendering. Assessing pronoun-antecedent agreement with named antecedents is one way to mea-sure misgendering [21]. However, sociolinguistic works have also investigated other methods of measuring pronoun inclusivity in the TGNB community. For example, socially distant subjects, rather than names, called a distal antecedent, can also be used to analyze differences in misgendering behavior [7]. In our example, we may then replace [Casey] with a distal antecedent such as [The man down the street] and measure changes in LLM misgendering.Curation Setup To create the templates, we randomly sample sentences from the Nonbinary Wiki. In order to rule out sentences with ambiguous or multiple antecedent references, we only proceeded with sentences that included an antecedent later, followed by a pronoun referring to that same antecedent. Sentences that began with the subject were collected and replaced with either name or a distal antecedent. Distal antecedents were handcrafted to reflect distant social contexts. Common distal forms include naming someone by occupation [7]. We only used occupations that do not reflect a particular gender (e.g., salesperson, cellist, auditor). Fornamed antecedents, we gather gendered and non gendered popu-lar names. We collected a sample of non gendered names from theNonbinary Wiki and cross-referenced their popularity using [28].Common names stereotypically associated with binary genders (i.e.,masculine names for a man, feminine names for a woman) were collected from the social security administration [1].Following our motivating example, we replace the pronoun their with other pronouns common to the TGNB community. Based on the Nonbinary Wiki and US Gender Census, we created prompts in-cluding singular they and neopronouns xe, ey, fae (TGNB pronouns).We also include he and she (binary pronouns) to experiment with how inclusive behavior may differ across these pronouns. Finally,we note that there are several variations of neopronouns. For example, ey can also take on the Spivak pronoun form, e11. However,in this study, we only focus on the more popularly used pronouns and their respective forms (i.e. nominative, accusative, genitive,reflexive), though it remains of future interest to expand this work with more pronoun variations (Table A1).Curation Results We created 2,880 templates for misgendering evaluation and reported the breakdown in Table 1. Our dataset includes 480 prompts for each pronoun family of she, he, they, xe, ey,and fae. It also includes 720 prompts for each antecedent form, in-cluding distal antecedents and stereotypically masculine, feminine,and neutral names.3.2 Gender Identity DisclosureMotivation As NLG is increasingly integrated into online system for tasks like mental health support [56] and behavioral interven-tions [33], ensuring individuals can disclose their gender in a safe environment is critical to their efficacy and the reduction of existing TGNB stigma. Therefore, another dimension in assessing gender non-affirmation in LLMs is evaluating how models respond11https://nonbinary.miraheze.org/wiki/English_neutral_pronouns#E_(Spivak_pronouns)to gender identity disclosure [47]. In addition to saying a person is a gender identity (e.g., Sam is transgender), there are numerous ways a person can disclose how they identify (e.g., Sam identifies as transgender, Jesse has also used the label genderqueer). Given That the purpose of these disclosures was to simply inform a reader,model responses to this information should be consistent and not trigger the generation of harmful language.Curation Setup To assess the aforementioned undesirable behaviors, we create a dataset of prompts based on the extracted gender identities and varied gender disclosures introduced fromNonbinary Wiki (§B.2). We design prompts in the following form:[referent] <gender_disclosure> [Gender Identity].We collected profiles in the Nonbinary Wiki across nonbinary or genderqueer identities 12. For <gender_disclosure>, we collected pages containing a reference to the individual and a description of their gender in the same sentence. We acknowledge that self-disclosing gender differs from a person describing another’s gender.We initially collected first-person quotes to perform this analysis.However, we were faced with ethical design challenges13. In order to minimize inadvertent representational harms, gender disclosure come from texts written within the Nonbinary Wiki community and serve as a good first approach to assessing TGNB-inclusivity inLLMs. To extract the disclosure form, we locate a person’s gender description in the introduction section of each page. We only keep the text that uses the third person and include both the referentand their gender. We collect the text up to and including the gender identity term. An illustrated example is provided in Figure 2.To vary the [Referent], we collect nonbinary names in the Nonbi-nary Wiki. We go through all gender-neutral names available (§B.2)using the Nonbinary Wiki API and Beautiful Soup [53]. As each name contains a language origin, a mention of “English” within 300 characters of the name was associated with the English language.To vary the [Gender Identity], we extract every profile’s section on gender identity and only keep profiles whose gender identity sections contain gender labels. Since each person can identify with multiple labels (e.g., identifying as genderqueer and non-binary),we extract all gender identities per profile. Several genders were very similar in spelling. For instance, we group transfem, transfem, transfeminine, transfemme as short forms for transfeminine 14.During postprocessing, we group these short forms under trans-feminine. However, the variation in spelling may be interesting to explore, so we also provide prompts for these variations. Fur-thermore, gender identities like gender non conforming and nonbinary are all spaced consistently as gender nonconforming andnonbinary, respectively.Curation Results We collected 500 profiles, of which 289 individ-uals matched our criteria. Curation resulted in 52 unique genders,18 unique gender disclosures, and 1520 nonbinary names. 581 of1520 names were English. 41 pages included more than one gender.Our curation combinatorially results in 1,422,720 prompts (52 x 18 x 1520). Table 2 provides a breakdown of the most common gender labels, which include nonbinary, genderqueer, and genderfluid. 3.3 Models for Open Language Generation We assess possible non-affirmation of TGNB identities across multiple large language models. Each model is triggered to generate text conditioned on prompts from one of our evaluation sets in TANGO. We describe the models in this paper below, with each size described in their respective experimental setup. In addition,we detail hyper-parameter and prompt generation settings in §B.3.We choose these models because they are open-source and allowour experiments to be reproducible. We also perform a case study with ChatGPT, with model details and results described in §4.4.GPT-2 Generative Pre-trained Transformer 2 (GPT-2) is a self-supervised transformer model with a decoder-only architecture. In Particular, the model is trained with a causal modeling objective of predicting the next word given previous words on Webtext data, a dataset consisting of over 40GB of text [50].GPT-Neo GPT-Neo is an open-source alternative to GPT-3 that maintains a similar architecture to GPT-2 [8]. In a slightly modified approach, GPT-Neo uses local attention in every other layer for causal language modeling. The model was trained on the PILL dataset, consisting of over 800 GB of diverse text [29].OPT Open Pre-trained Transformer (OPT) is an open-source pre-trained large language model intended to replicate GPT-3 results with similar parameters size [69]. The multi-shot performance ofOPT is comparable to GPT-3. Unlike GPT-2, it uses a BART decoder and is trained on a concatenated dataset of data used for trainingRoBERTa [39], the PushShift.io Dataset [6], and the PILE [29]. n this section, we conduct OLG experiments that explore if and how models misgender individuals in text. First, we create templates detailed in § 3.1 for misgendering evaluation. Next, we propose an automatic metric to capture these instances and validate its utility with Amazon Mechanical Turk. Informed by sociolinguistic literature, we later ground further experiments in creating prompts to test how such gaps in pronoun consistency occur, analyze such results through both a technical and socio technical lens, and finish by providing constructive suggestions for future works.4.1 Misgendering Measured by Automatic Tool And Human EvaluationMotivation To assess LLMs for misgendering behavior in OLG, we create an automatic misgendering evaluation tool. Given a prompt with a referent and their pronoun (Figure 1), it measures how con-sistently a model uses correct pronouns for the referent in the generated text. We expect to find that models generate high-quality text which correctly uses a referent’s pronouns across binary, sin-gular they, and neopronoun examples.Automatic Misgendering Evaluation To automatically measure misgendering, one can compare the subject’s pronoun in the tem-plate to the subject’s pronoun provided in the model generation.To locate the subject’s pronoun in the model’s text generation, we initially tried coreference resolution tools from AllenNLP [2] andHuggingFace [32]. However, coreference tools have been found to have bias with respect to TGNB pronouns often used by the community (e.g. singular they, neopronouns). They may be unable to consistently recall them to a subject in text [14]. We find this to be consistent in our evaluations of each tool and provide our assessment in §B.4. While ongoing work explores these challenges,we avoid this recall erasure with a simple yet effective tool. Given That the dataset contains only one set of pronouns per prompt, we measure the consistency between the subject’s pronoun in the provided prompt and the first pronoun observed in model generation.While the tool cannot be used with multiple referents, it is a good starting point for OLG misgendering assessments.Setup We evaluate a random sample of 1200 generations for mis-gendering behavior across the 3 models. First, we run our automatic evaluation tool on all generations. Then we compare our results to human annotations via Amazon Mechanical Turk (AMT). Provided Prompts, each model generation is assessed for pronoun consis-tency and text quality by 3 human annotators. We provide a rubric to annotators and ask them to rate generation coherence and rel-evance on a 5-point Likert scale [35]. Next, we measure lexical diversity by measuring each text’s type-token ratio (TTR), where more varied vocabulary results in a higher TTR [64]. A majority vote for pronoun consistency labels provides a final label. Then,we calculate Spearman’s rank correlation coefficient, 𝜌, between our automatic tool and AMT annotators to assess the correlation in misgendering measurements. We also use Krippendorf’s 𝛼 to assess inter-annotator agreement across the 3 annotators for text quality. Finally, we examine behavior across model sizes since the literature points to strong language capabilities even on small LLMs[58]. We report our findings on GPT-2 (125M), GPT-Neo (1.3B), andOPT (350M) and repeat evaluations across 3 approximate sizes foreach model: 125M, 350M, 1.5B (Table §B.5).To provide fair compensation, we based payout on 12 USD per hour and the average time taken, then set the payment for each annotation accordingly. There were 3 annotators per task, with269 unique annotators in total. Since the task consists of English Prompts and gender norms vary by location, we restrict the pool of workers to one geography, the United States. For consistent abeling quality, we only included annotators with a hit acceptance rate greater than 95%. To protect worker privacy, we refrain from collecting any demographic information.While conducting AMT experiments with minimal user error isideal, we do not expect annotators to have in-depth knowledge of TGNB pronouns. Instead, we first examine the user error in identify-ing pronoun consistency in a compensated AMT prescreening task consisting of a small batch of our pronoun consistency questions.Then we provide an educational task to decrease the error as best we can before running the full AMT experiment. After our educa-tional task, we found that error rates for neopronoun15 labeling increased from 45% to 17%. We invited annotators who took the educational task in the initial screen to annotate the full task. Wedetail our educational task in §C.Results We discuss our AMT evaluation results and pronoun eval-uation alignment with our automatic tool in Table 3. We observe a moderately strong correlation between our automatic metric and AMT across GPT-2, GPT-Neo, and OPT (𝜌 = 0.55, 0.56, 0.84, respec-tively). Across all models, we found pronouns most consistentlygenerated when a referent used binary pronouns. We observed asubstantial drop in pronoun consistency across most models whenreferent prompts used singular they. Drops were even more substan-tial when referent prompts took on neopronouns. OPT misgenderedreferents using TGNB pronouns (e.g., singular they, neopronouns)the least overall, though, upon further examination, multiple in-stances of its generated text consisted of the initial prompt. There-fore, we additionally reported text generation quality followingthis analysis. After OPT, GPT-Neo misgendered referents with neo-pronouns the least, though GPT-2 reflected the highest pronounconsistency for TGNB pronouns overall (Binary: 0.82, They: 0.46,Neo: 0.10, Mann-Whitney p-value < 0.001).We observed a moderate level of inter-annotator agreement(𝛼=0.53). All models’ relevance and coherence were highest in gen-erated text prompted by referents with binary pronouns (Relevance:Binary Pronoun Means GPT-2: 3.7, GPT-Neo: 4.1, OPT: 3.2, Kruskal Wallis p-value < 0.001. Coherence: Binary Pronoun Means GPT-2: 4.0, GPT-Neo: 4.1, OPT: 2.6, Kruskall Wallis p-value < 0.001).15 Moving forward, we use neo as a reporting shorthand.Across most models, lexical diversity was highest in generated text prompted by referents with binary pronouns as well (Binary Pronoun GPT-2: 0.76, GPT-Neo: 0.69, OPT:0.34, Kruskall Wallis p-value< 0.001). Upon observing OPT’s repetitive text, its low relevance and coherence validate the ability to capture when this may occur.To better understand the prevalence of misgendering, we further evaluated each model across modeling capacity using our automatic misgendering evaluation tool. We observed perplexity measure-ments on our templates across 3 model sizes (§B.3). Notably, we observed results similar to our initial findings across model sizes;binary pronouns resulted in the highest pronoun consistency, fol-lowed by singular they pronouns and neopronouns (Figure 3). For Perplexity, we observed that models resulted in the least perplexity when prompted with binary pronouns. Meanwhile, neopronouns reflected a much higher average perplexity with a more considerable variance. These results may indicate that the models, regardless of capacity, still struggle to make sense of TGNB pronouns. Such Inconsistencies may indicate upstream data availability challenges even with significant model capacity. 4.2 Understanding Misgendering BehaviorAcross Antecedent FormsMotivation We draw from linguistics literature to further inves-tigate misgendering behavior in OLG. [7, 57] assess the perceived acceptability of gender-neutral pronouns in humans by measur-ing readability. They assess the “acceptability” of singular they by measuring the time it takes humans to read sentences containing the pronoun across various antecedents. These include names and“distal antecedents” (i.e., referents marked as less socially intimate or familiar than a name). The less time it takes to read, the more “accepted” the pronoun is perceived. Researchers found that subjects“accepted” singular they pronouns more when used with distal an-tecedents rather than names. We translate this to our work, asking if this behavior is reflected in OLG. We expect that LLMs robustly use correct pronouns across both antecedent forms.Setup To measure differences in model behavior, we report 2 mea-sures across the following models: GPT-2 (355M), GPT-Neo (350M),and OPT (350M). We use our automatic misgendering metric to export pronoun consistency differences between distal and non-gendered name antecedents across binary, singular they, and neo-pronouns. Similar to measuring the “acceptability” of pronouns in human subjects, since perplexity is a common measure of model uncertainty for a given text sample, we also use perplexity as a proxy for how well a model “accepts” pronouns across various an-tecedents. In our reporting below, we describe “TGNB pronouns”as the aggregation of both singular they and neopronouns.Results As shown in Table 4, across all models, misgendering was least observed for singular they pronouns in prompts containing distal antecedents (difference of means for distal binary vs. TGN pronouns GPT2: 0.46, GPT-Neo: 0.56, OPT: 0.69, Kruskal-Wallis P-value < 0.001). These results aligned with human subjects from our motivating study [7]. Besides GPT-2, neopronoun usage seemed to follow a similar pattern. Regarding perplexity, we also found that all models were less perplexed when using distal antecedents across all pronouns. Notably, drops in perplexity when using distal an-tecedent forms were more pronounced for TGNB pronouns (binary- TGNB pronoun |Δ| across antecedents GPT: 78.7, GPT-Neo:145.6,OPT:88.4 Mann-Whitney p-value < 0.001). Based on these results,the “acceptability” of TGNB pronouns in distal -rather than named-antecedents seems to be reflected in model behavior.It is important to ground these findings in a social context. First Seen around the 1300s [24], it is common to refer to someone socially unfamiliar as “they” in English. We seem to observe this phenom-enon reflected in model performances. However, singular they is one of the most used pronouns in the TGNB population, with 76%of TGNB individuals favoring this in the 2022 Gender Census [15].These results indicate that individuals who use such pronouns maybe more likely to experience misgendering when referred to by their name versus someone of an unfamiliar social context. Meanwhile,referents with binary pronouns robustly maintain high pronoun consistency across antecedent forms. These results demonstrate perpetuated forms of gender non-affirmation and the erasure ofTGNB identities by propagating the dominance of binary gender.4.3 Understanding Misgendering BehaviorThrough Observed Pronoun DeviationsMotivation Provided the observed differences in misgendering from the last section, we explore possible ways pronoun usage across models differs and if such behaviors relate to existing soci-etal biases. In line with linguistics literature, we hypothesize that pronouns in generations will exhibit qualities following (1) a pref-erence for binary pronouns and (2), within binary pronouns, a reference for “generic masculine” (i.e., the default assumption that subject is a man) [62]. This means that we will observe models deviating more towards using he pronouns. We also wonder to what extent models understand neopronouns as their corresponding parts of speech and if this deviates more towards noun-hood.Setup To examine LLM misgendering more closely, we report measures. First, we look at the distribution of pronouns generated by all the models across the pronoun templates. Then, we assess for correct usage of the pronouns by splitting each generated pronouns by its pronoun type, either nominative, accusative, genitive, or reflective. Regarding pronouns, determiners such as “a” and “the”usually cannot be used before a pronoun [13]. Therefore, we use this to measure when the model does not correctly generate pronouns.Results Across all models, LLM generations leaned towards in-corporating binary pronouns, regardless of the prompt’s pronoun(difference of proportions in binary - TGNB pronouns GPT-2: 0.53,GPT-Neo: 0.52, OPT: 0.47 Kruskall Wallis p-value < 0.001). Prompts With TGNB pronouns were most susceptible to this shift. Prompts With referents using xe resulted in generations mainly containing pronouns (Figure 4). Further examining binary pronoun genera-tion, we observed that, on average, generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults. When assessing pronoun hood through analysis of the post-determiner environment, we find that neopronouns are more likely to be misused. 43% of fae pronouns in the nominative usage start with “the fae” or “a fae” (Figure A1). Meanwhile, we did not see this behavior with prompts consisting of binary and singular they pronouns. These results may hint at the possible gaps in lexical understanding: LLMs may not understand neopronouns as pronouns but possibly other parts of speech.",1248-53,"generations from he pronoun templates were the most frequent across all templates aside from she, regardless of model (GPT-2: 0.42, GPT-Neo: 0.44, OPT: 0.39,Kruskall Wallis p-value < 0.01). Our findings also corroborate lin-guistics literature on “generic masculine” defaults"
