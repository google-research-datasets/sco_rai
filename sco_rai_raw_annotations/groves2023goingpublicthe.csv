,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{groves2023goingpublicthe,
    author = {Lara Groves and Aidan Peppin and Andrew Strait and Jenny Brennan},
    title = {Going public: the role of public participation approaches in commercial AI labs},
    year = 2023
}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-19, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,ParticipatoryAIPractitioners,Agent,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,Participants,
10,PereceptionOfSocialGood,Causal_Theory,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"public participation is viewed asserving societally ’good’ ends,",
11,LackOfPracticalUnderstanding,Perceived_Need,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,lacks clear and shared under-standing of practices.,
12,Obstacles,Perceived_Problem,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.",
13,LackOfClearContext,Perceived_Need,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,products or research that lack a clear context.,
14,ObligationToEnsureSocialBenefit,Perceived_Problem,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies",
15,ProfitMotive,Strategy,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,the lens of profitability or business mission,
16,ExplanatoryChallenge,Perceived_Problem,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,challenges of explaining the value and role that participation can play to others in the firm,
17,Performativity,Perceived_Problem,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,concerns of a performativity around labels such as ‘responsible AI’,
18,LackOfPreparation,Perceived_Problem,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,did not feel fully equipped to report on their organization’s activity in the area of participatory AI,
19, , , , , ,
20, , , , , ,
21,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
22,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
23,PereceptionOfSocialGood,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"Within commercial AI labs, public participation is viewed asserving societally ’good’ ends"
24,LackOfPracticalUnderstanding,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of "
25,Obstacles,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives."
26,LackOfClearContext,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,Public participation in AI labs is complicated by products or research that lack a clear context.
27,ObligationToEnsureSocialBenefit,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,"participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies"
28,ProfitMotive,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission
29,ExplanatoryChallenge,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,interviewees noted challenges of explaining the value and role that participation can play to others in the firm
30,Performativity,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,One interview noted concerns of a performativity around labels such as ‘responsible AI’
31,LackOfPreparation,constrainsAgent,ParticipatoryAIPractitioners,"We interviewed nine practitioners working in large, medium and start-up commercial AI labs developing both products and research, who may be involved in planning or implementation of public engagement / participation projects or be expected to carry forward findings of public partic-ipation projects into research and or product development. For Additional background, we also interviewed three subject-matter experts across participatory design, participatory AI and public en-gagement methods, and with knowledge of tech industry practice.One of these three experts is employed by a technology-focused non-profit, two are currently employed by academic institutions;one of these two had recent previous employment in a commercial lab. All three have authored papers pertaining to participation inAI. See Table 1 for participant IDs. Our interview questions were split into four sections. We asked participants: (1) How they understand public participation; (2) What they think public participation in AI is for; (3) What methods or approaches they have used in their work,or seen in use across the sector, and;(4) Details of their role, their organization’s work culture, re-sources, and its propensity to fund or conduct participatoryworkParticipants were recruited either directly (selected based on previous demonstrable interest in ‘participatory AI’, ‘responsible AI or similar fields, and/or were part of the authors’ existing industry networks) and through snowball recruitment from recommenda-tions from interviewees. Interviews lasted 60 minutes and took place virtually, using video conferencing software from September2022 to January 2023, and were transcribed using a speech-to-text transcription software service. Three interviewees did not consent for their interview quotes to be used in this paper. Since all partici-pants were in continuous employment at the time of participation,they were not offered additional payment for their time. Interview data was analyzed using a constructivist qualitative the-matic analysis that draws heavily on a ‘theoretically flexible’ ap-proach set out by Braun and Clarke (2006), that specializes in under-standing and reporting repeated patterns, particularly in terms of institutional/organizational behaviors [16]. Using a constructivist epistemology allowed us to approach the data with an understand-ing that meaning and experience are socially (re)produced [19].Following this paradigm, we coded our data and constructed our themes according to a ‘latent classification’ approach [16] surfacing implied beliefs.The interviews were coded by the lead author using data analysis software. We chose not to set prescriptive benchmarks around prevalence of codes, or whether codes directly related to the RQs. After an initial batch of 71 codes generated, a re-coding process resulted in 56: some codes were felt to be too broad, in other cases,two substantively similar codes were merged (e.g. ‘building rapport to ‘relationship building’), and antonyms such as ‘inclusion’ and exclusion’ were felt to be usefully interpreted dialectically and coded as single entities.From these 56 codes, reproduced across Tables 2 and 3, we iden-tified six main themes that corresponded to different research ques-tions:(1) Internal factors(2) Commercial factors(3) Field-level factors(4) Societal and moral factors(5) Purpose of participation(6) Participatory approachesFrom the data, we surfaced many different operational consid-erations and personal values/beliefs that practitioners suggested are (or might be) impactful for the adoption of public participation.Factors were reported to emanate from the level of the firm (‘Inter-nal’), or externally (‘Field-level’), and pertained to business mission(‘Commercial’) or relationship to people and society (‘Societal and moral’). These are categorized as ‘factors’ over the more directionale.g. ‘blockers’ or ‘drivers’ to avoid setting up a simplistic binary for phenomena not experienced by all participants universally. Some Codes appear in different themes, highlighting the porous bound-aries between these themes. Theme 5 and Theme 6 concern methods and approaches for, and purpose of, participation, and therefore correspond explicitly with RQ1 and RQ2 of our study. At the time of research, all the authors were employed by an inde-pendent research institute that conducts evidence-based research on data and AI in policy and practice, with a core organizational belief that benefits of data and AI must be justly and equitably distributed, and must enhance individual and social wellbeing. As part of the organizational remit, the institute collaborates with tech-nology companies in a research capacity, i.e. using industry as a site of study. It does not accept funding from technology compa-nies. The authors live and reside in the UK, and two of the four authors are British, one is British and Irish and one is American.We adopt a sociotechnical conception of AI, understanding that the technical elements of AI – machine learning, neural networks, etc –are inherently interrelated with social, political and cultural factors,principles and motivations (see for example Mohamed et al.) [59]. Based on our review of the literature, we asked our interview subjects how commercial AI labs understand participatory AI ap-proaches and the obstacles they have faced implementing these practices in the development of AI systems:(1) Within commercial AI labs, public participation is viewed asserving societally ’good’ ends, but may also have a strong business purpose (2) Public participation in AI industry lacks clear and shared under-standing of practices. Participants did not identify many participa-tory methods they use, but rather tended to list methods they had heard of (3) Public participation in AI labs faces various obstacles: resource-intensity, atomisation, exploitation risk and misaligned incentives.(4) Public participation in AI labs is complicated by products or research that lack a clear context.“We do a lot of AI for social good projects at [large company]. But I’malways wondering why we need the qualifier of AI for social good.”[P3]Interviewees, including the practitioners working on ‘participa-tory AI’ and adjacent topics, view participation and participatory approaches positively, with several associating these practices with doing good in the world’, an indication of company legitimacy oras a commitment to accountability. Another participant described the pull to embed participatory approaches as an ‘obligation’, to ensure the company are achieving socially beneficial outcomes with their technologies:“We, as a corporation, building or researching a technology that has the potential to solve problems for people, have an obligation to engage folks from various backgrounds to help us understand the different problems they face.” [P7]Some interviewees report viewing public participation in thelabs through the lens of profitability or business mission:“It should be for good business, right? Engaging with people should help you build a product that addresses their wants and needs better which in turn, makes your company more profitable.” [P2]This view more closely follows the argument that increasing par-ticipation in corporate tech contexts presents an opportunity to increase access to technology: unsurprisingly, if your goal is to build better tech, then making it work better for more people is an attractive prospect. However, other participants expressed frustra-tion that this would be likely to be the only logic that would wash with corporate shareholders (who, as one interviewee suggested,would not find any reason to complain if public participation was not conducted at all). In larger companies, interviewees noted challenges of explaining the value and role that participation can play to others in the firm. Those using these methods were trying to resolve concerns around, for example, bias and fairness, but often found that they had to reframe these objectives from the perspec-tives of how these methods could provide an increasing return on revenue. One interview noted concerns of a performativity around labels such as ‘responsible AI’: “There’s concern about being exploitative in using that knowledge todo this sort of marketing veneer of responsible AI, then we’re still just going to make money on everything.” [P3] “We take that there are many different approaches to public participa-tion [at the company]. Some are more kind of focused on participatory annotation of data and co-production of AI systems. I think my work is more focused on vision setting for the future of AI.” [P7] Our research corroborates findings from the literature of an enduring lack of consensus around participatory approaches in practice[8, 26]. Interviewees were asked ""what approaches to participation have you used in your work or practice?"" Some interviewees were able to talk about approaches they’d personally used for certain research/development projects, but more usually, would recall (of-ten cursory) detail about specific projects or ideas in either their organization or across the sector, rather than any direct experience.Overall, interviewees cited 1 different methods they were familiar with or had used – see Table 3.The method interviewees cited most often was a form of consul-tation with people outside the company, generally domain experts rather than members of the public, usually to solicit feedback on the design or usability of products. Most interviewees recognised that participation could have multiple dimensions, with a few specifi-cally using the word ‘spectrum’. Two interviewees suggested that open sourcing machine learning models, as a kind of mass partici-pation predicated on widespread involvement, might constitute a participatory approach. Despite overall understanding and knowledge of types of ap-proaches that could be used in AI development, the important accompanying finding is that most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI’. While we cannot rule out that commercial AI labs are using participatory methods that we are unaware of, these findings suggest that, at best, interviewees did not feel comfortable discussing specific examples of these methods with us, or had no awareness of these methods being used in their companies – and at worst, that such methods are not being used at all. Given that most interviewees self-selected to participate on the basis of their familiarity with public participation in AI (see ‘Methodology’), it would appear that the most likely scenario is that there is little use of participatory approaches to AI in industry. ",1163-4,most interviewees did not feel fully equipped to report on their organization’s activity in the area of participatory AI
