,A,B,C,D,E,F
1,~~~ Paper Details ~~~~, , , , ,
2,bibliographicCitation,"{eyert2023, author = {Eyert, Florian and Lopez, Paola},
title = {Rethinking Transparency as a Communicative Constellation},
year = {2023}}", , , ,
3,~~~ Annotator Details ~~~~, , , , ,
4,identifier,dk, , , ,
5,role,annotator,DO NOT CHANGE, , ,
6,generatedAtTime,2023-12-13, , , ,
7,~~~ Class Instance / Individual Annotations starts below ~~~~, , , , ,
8,individualName,type,sourceExcerpt,sourcePageNumber,sourceExtractedDescription,
9,JobSeekersAlgorithm,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,a predictive classification system to segregate job-seekers into different categories with differing eligibility for support.,
10,JobSeekersAlgorithm,Perceived_Problem,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,a predictive classification system to segregate job-seekers into different categories with differing eligibility for support.,
11,JobSeekersAlgorithm,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,a predictive classification system to segregate job-seekers into different categories with differing eligibility for support.,
12,AustrianPublicEmploymentService,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short),
13,AustrianMedia,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,Austrian media,
14,ResearchInstitute,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,the research institute that built the algorithmic system,
15,Scientists,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,Scientists,
16,LackOfTransparency,Perceived_Need,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].",
17,ArbeitPlus,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus,",
18,Caseworkers,Agent,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,case workers,
19,ReportsOnImplementation,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool",
20,TechnicalDetails,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,some technical details were published in the form of a 15-page document,
21,Criticism,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].",
22,PositionPaper,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,published a position paper that included explanations about the AMS algorithm’s decision rationale,
23,DecisionSimulator,Artifact,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"One article, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm ",
24, , , , , ,
25,~~~ Property / Axiom / Triple Annotations starts below ~~~~, , , , ,
26,annotatedSource,annotatedProperty,annotatedTarget,sourceExcerpt,sourcePageNumber,sourceExtractedDescription
27,AustrianPublicEmploymentService,hasProducedArtifact,JobSeekersAlgorithm,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into different categories with differing eligibility for support.
28,JobSeekersAlgorithm,constrainsAgent,Caseworkers,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers"
29,AustrianMedia,hasProducedArtifact,ReportsOnImplementation,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool"
30,ResearchInstitute,hasProducedArtifact,TechnicalDetails,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic system"
31,Scientists,hasProducedArtifact,Criticism,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3]."
32,LackOfTransparency,constrainsAgent,JobSeekersAlgorithm,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3]."
33,AustrianMedia,hasProducedArtifact,DecisionSimulator,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. One article, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm "
34,ArbeitPlus,hasProducedArtifact,PositionPaper,"Several years ago, the Austrian Public Employment Service (Arbeits-marktservice in German and AMS for short) planned to introduce a predictive classification system to segregate job-seekers into dif-ferent categories with differing eligibility for support. The group placement was to be made according to the job-seeker’s chances on the labor market, as predicted by the system using different data about job-seekers, including personal data on sensitive attributes such as, e.g., gender, age and health status. The classification system was not supposed to decide automatically, but to be used as a deci-sion support tool for case workers. Currently, the case of the AMSalgorithm, as it came to be known in the media, is pending before the Austrian Supreme Administrative Court due to the question of its accordance with the EU’s General Data Protection Regulation.In the following, we sketch the communicative constellation at work and the efforts by multiple actors in furthering meaningful transparency and public discourse around the AMS algorithm.In October 2018, Austrian media reported about the implementa-tion of the algorithmic system [77], and published interviews with responsible board member of the AMS explaining the advantages of the data-driven decision support tool [78, 87]. A few days later,some technical details were published in the form of a 15-page document by the research institute that built the algorithmic sys-tem [46]. The document includes some technical descriptions on the features that the algorithm used for decision-making, such as gender, age, health status, nationality, as well as some information about the ways in which the classification was supposed to function. Scientists later criticized the lack of technical transparency, as only little information was disclosed in the document [23] – information that was even, to some degree, misleading [3].Still, some fundamental aspects of the classification and the ensuing rationale of decision-making could be inferred from the published document. However, these fundamental aspects had to be rendered understandable and, thus, transparent to the broader public. Several groups of actors were crucial in sparking a larger debate: science and tech journalists, activists, and critical scientists,among others. Science and tech journalists played a vital role in communicating the algorithmic system and its potential negative effects, such as the automation of discriminatory practices, to the broader public. They reported on the algorithm and used different techniques to make its decision rationale more understandable. Onearticle, for example, created an interactive application so that read-ers could click on and, thus, try out different combinations of data entries to calculate their chances on the labor market according to the AMS algorithm [51]. This reconstruction of the AMS algo-rithm is based on incomplete information and mimics only one of the proclaimed 96 models for classification, as the technical details were not made fully transparent. Nevertheless, this technical tool served the purpose of science communication by acquainting thereaders with the decision rationale without assuming technical knowledge. In this constellation, they enabled readers to view the system critically – an ideal example of epistemic transparency as a facilitator of public critique. This interactive and easy-to-use appli-cation also had more than double the comments than an article that only explained the published technical details in a text [79]. This Demonstrates the interest by the public – interest that was elevated by the availability of tools for critique in discourse Scientists, too, criticized the algorithmic system. From the doc-ument that was published, they concluded that the implementa-tion might entail negative effects, such as the built-in potential for discrimination. Scientists served as translators in two ways: via interviews with media outlets when the application of the AMSalgorithm was announced [88, 89], and, after the application of the algorithmic system was decided on, in blogs of media outlets[23, 75]. Scientific publications were written that engaged with,and critiqued, the AMS algorithm (e.g., [2, 60, 70]). The responsible board member of the AMS published blog articles responding to the public critique and defending the system [54, 55] (see also [18]).Twitter users and activists criticized the tool as well (e.g., [27, 45]).The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale[5]. The NGO epicenter.works submitted inquiries to the AMS under a legal title that required the AMS to answer and, thus, to disclose more details [31]. The NGO also started a campaign including press conferences and a video that explained, in an easy-to-understand fashion, the potential risks of the AMS algorithm, thereby translat-ing and making available the effects and the critique of the algo-rithm to the broader public [32]. The case of the AMS algorithm gained a lot of attention – also internationally – and, hopefully,sparked general and far-reaching debates about the caution with which one has to proceed when developing and implementing an algorithmic system, especially in a sensitive area.This case study shows, on the one hand, the multi-actor and multi-stage nature, and, to a degree, the messiness of the quest or transparency as a communicative constellation. It is the con-stellation of several actors that enabled a broader discourse. Thiscase also shows the potential for politicization, even in the absence of comprehensive technical transparency: politicization occurred even though only some details about the algorithmic classification were made public. Transparency in the broad sense served as a vehicle for resistance against the implementation of the algorithmic system because it didn’t have to rely on complete technical details.The conclusions about the decision rationale, together with their translation, were enough to initiate public controversy and debate.One can imagine what kind of discourse can be made possible with more transparency – not only ex post, but ex ante: a broad discourse about the implementation of algorithmic systems them-selves before they are decided upon. Taking transparency seriously,the respective political decision-makers and the state agency actors as well as the practitioners who developed the tool would have contributed to the transparency of the algorithmic system before it's decided implementation. Further, it would have been their obli-gation to translate the technical details to the broad public and thereby facilitate a wider debate. This debate, in turn, could have had an effect on the system’s development (see, e.g., [70]) or subsequent policy decisions, as discourse, of course, is not an end in itself. ",450-1,"The Austrian network of non-profit, labor market oriented social integration enterprises, arbeit plus, published a position paper that included explanations about the AMS algorithm’s decision rationale"
